{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network (GAN)\n",
    "Since GANs were introduced in 2014 by Google Researcher Ian Goodfellow, the tech has been widely adopted in image generation and transfer. After some early wiry failures, GANs have made huge breakthroughs and can now produce highly convincing fake images of animals, landscapes, human faces, etc.\n",
    "\n",
    "Our GAN uses from the folowing project, however our GAN network uses Fully Connected layers and No Convolutions layers:\n",
    "\n",
    "-   Radford, Alec, Luke Metz, and Soumith Chintala. “Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks.” ArXiv:1511.06434 [Cs], January 7, 2016. http://arxiv.org/abs/1511.06434"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:54:18.282897Z",
     "start_time": "2020-04-27T18:54:17.999223Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from PIL import Image\n",
    "from typing import Set\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## GPU Device Configuration\n",
    "Then, we set up and configure our computational devices: \n",
    "Whether we use GPU or perform the calculation on CPU.\n",
    "we use the torch.devices() and torch.cude.is_available() functions to configure our computational devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:54:19.807065Z",
     "start_time": "2020-04-27T18:54:19.783824Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU training available\n",
      "Index of CUDA device in use is 0\n"
     ]
    }
   ],
   "source": [
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    # inbuilt cudnn auto-tuner searches for best algorithm for hardware\n",
    "    # cuddn.benchmark should be set to True when our input size does not vary\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(\"GPU training available\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(f\"Index of CUDA device in use is {torch.cuda.current_device()}\")\n",
    "else:\n",
    "    print(\"GPU training NOT available\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Can only train on CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Configuration\n",
    "### Hyper parameters\n",
    "Set up Hyper Parameters that our model needs.\n",
    "\n",
    "We need to define several hyper parameters for our model:\n",
    "1. Latent size\n",
    "2. Hidden size\n",
    "3. Input image size\n",
    "4. Number of epochs\n",
    "5. Batch size\n",
    "6. Learning rate\n",
    "7  Beta1 for ADAM Optimizer\n",
    "8. Output Directory for generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:54:21.643803Z",
     "start_time": "2020-04-27T18:54:21.636481Z"
    }
   },
   "outputs": [],
   "source": [
    "class HyperParameter():\n",
    "    def __init__(self,\n",
    "                 latent_sz,\n",
    "                 in_img_size,\n",
    "                 in_img_channel=3,\n",
    "                 data_dir=\"../data/img_align_celeba\",\n",
    "                 output_dir=\"../generated_imgs\",\n",
    "                 lr=0.0002,\n",
    "                 beta1=0.5,\n",
    "                 epochs=100,\n",
    "                 batch_sz=64,\n",
    "                 d_trained_wt_dir=\"../discriminator_trained_weights\",\n",
    "                 g_trained_wt_dir=\"../generator_trained_weights\"):\n",
    "        self.latent_size = latent_sz\n",
    "        self.learning_rate = lr\n",
    "        self.beta1 = beta1\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_sz\n",
    "        self.input_img_channel = in_img_channel\n",
    "        self.input_img_size = in_img_size\n",
    "\n",
    "        self.discriminator_trained_weight_dir = d_trained_wt_dir\n",
    "        self.generator_trained_weight_dir = g_trained_wt_dir\n",
    "        self.output_dir = output_dir\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "        os.makedirs(self.discriminator_trained_weight_dir, exist_ok=True)\n",
    "        os.makedirs(self.generator_trained_weight_dir, exist_ok=True)\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"latent_size: {self.latent_size}\\n\" + \\\n",
    "               f\"learning_rate: {self.learning_rate}\\n\" + \\\n",
    "               f\"beta1: {self.beta1}\\n\" + \\\n",
    "               f\"input_img_size: {self.input_img_size}\\n\" + \\\n",
    "               f\"input_img_channel: {self.input_img_channel}\\n\" + \\\n",
    "               f\"epochs: {self.epochs}\\n\" + \\\n",
    "               f\"batch_size: {self.batch_size}\\n\" + \\\n",
    "               f\"data_dir: {self.data_dir}\\n\" + \\\n",
    "               f\"output_dir: {self.output_dir}\\n\" + \\\n",
    "               f\"discriminator_trained_weight_dir: {self.discriminator_trained_weight_dir}\\n\" + \\\n",
    "               f\"generator_trained_weight_dir: {self.generator_trained_weight_dir}\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Hyper Parameter Class can be set up like so**\n",
    "\n",
    "```python\n",
    "hyper_parms = HyperParameter(latent_sz=100, in_img_size=64, in_img_channel=3, output_dir=\"../generated_imgs\", lr=0.0002, beta1=0.5, epochs=100, batch_sz=64)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "##  Image processing\n",
    "Then, we define a image preprocessing object that our dataloader can directly use this object to preprocess our data\n",
    "We use the pytorch API to preform the data processing.\n",
    "1. Use transforms.Compose()\n",
    "2. Use transforms.CenterCrop(160) \n",
    "3. Use transforms.Resize(64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:54:23.327317Z",
     "start_time": "2020-04-27T18:54:23.318531Z"
    }
   },
   "outputs": [],
   "source": [
    "img_data_transform = transforms.Compose([\n",
    "    transforms.CenterCrop(160),\n",
    "    transforms.Resize(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])  # Normalizes imgs in the range [-1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "##  Data Loading\n",
    "Next, we are going to load our data. \n",
    "### First, we need to prepare our data:\n",
    "#### we use the following command to download our data:\n",
    "\n",
    "```shell\n",
    "$ apt-get install p7zip-full # ubuntu\n",
    "\n",
    "$ brew install p7zip         # OSX\n",
    "\n",
    "$ python download.py\n",
    "```\n",
    "\n",
    "-----\n",
    "### Import the necessary library for data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:54:28.529615Z",
     "start_time": "2020-04-27T18:54:28.519374Z"
    }
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We first define several helper functions that can help use to load each item in the dataset.\n",
    "\n",
    "1.   We first create a list that contains all image files.    '.jpg', '.JPG', '.jpeg', '.JPEG', '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP',.\n",
    "\n",
    "2.   We define function `is_image_file()` which takes the file name as the input:\n",
    "    <br />a. Return True if it is a valid image file else False\n",
    "    \n",
    "3.   We define `make_dataset()` function which takes a file path as the input:\n",
    "    <br />a. Go over the path and find files\n",
    "    <br />b. If it is a valid img file, store it to a list\n",
    "    <br />c. Return the list\n",
    "    \n",
    "4.   Finally, create a function that is called default_loader()\n",
    "    <br />a. that will open the image and convert it to the RGB using Image.open() and convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:54:30.592607Z",
     "start_time": "2020-04-27T18:54:30.572699Z"
    }
   },
   "outputs": [],
   "source": [
    "VALID_IMG_EXTENSIONS = {\n",
    "    '.jpg', '.JPG', '.jpeg', '.JPEG', '.png', '.PNG', '.ppm', '.PPM', '.bmp',\n",
    "    '.BMP'\n",
    "}\n",
    "\n",
    "\n",
    "def _is_image_file(fpath, valid_img_ext: Set = VALID_IMG_EXTENSIONS) -> bool:\n",
    "    \"\"\"Validates if a file is an img file\"\"\"\n",
    "    _, img_ext = os.path.splitext(fpath)\n",
    "    return img_ext in valid_img_ext\n",
    "\n",
    "\n",
    "def make_img_dataset(root_dir, valid_img_ext: Set = VALID_IMG_EXTENSIONS):\n",
    "    \"\"\"Returns a list of valid img files after recursively chking in rootdir\"\"\"\n",
    "    img_dataset = []\n",
    "    for subdir, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if _is_image_file(file, valid_img_ext):\n",
    "                img_path = os.path.join(subdir, file)\n",
    "                img_dataset.append(img_path)\n",
    "\n",
    "    return img_dataset\n",
    "\n",
    "\n",
    "def default_loader(img):\n",
    "    \"\"\"Converts img file into RGB mode\"\"\"\n",
    "    try:\n",
    "        opened_img = Image.open(img)\n",
    "        return opened_img.convert('RGB')\n",
    "    except Exception as e:\n",
    "        print(f\"Exception: {e}. Skipping {img}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We then can use those helper functions to create our dataloader that load each item.  For this we creat a ImageDataset(data.Dataset) class\n",
    "\n",
    "1. This function is initialized with root, train transform, target transform and loader\n",
    "    <br /> a. We get all images using the utility functions we defined\n",
    "    <br /> b. If there are no valid images we raise an proper error\n",
    "    <br /> c. Print the length of valid data\n",
    "\n",
    "2. We need to define a __getitem__() function that take index as input\n",
    "    <br /> a. For the \"index\" element in the img list\n",
    "         i.   Apply the transform\n",
    "    <br /> b. Return the img and target.\n",
    "\n",
    "3. We define a __len__() function that retrun the length of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:54:32.225115Z",
     "start_time": "2020-04-27T18:54:32.218967Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 root_dir,\n",
    "                 transform=None,\n",
    "                 valid_img_ext: Set = VALID_IMG_EXTENSIONS):\n",
    "        self.transform = transform\n",
    "\n",
    "        self.face_dataset = make_img_dataset(root_dir, valid_img_ext)\n",
    "        if len(self.face_dataset) == 0:\n",
    "            raise IndexError(\"Face dataset is empty\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.face_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_path = self.face_dataset[idx]\n",
    "        image = Image.open(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We then define our data loader get_loader()\n",
    "#### This func has 5 arguments\n",
    "1. root\n",
    "2. batch size\n",
    "3. scale size (img_data_transform)\n",
    "4. number of workers\n",
    "5. shuffle\n",
    "\n",
    "<br /> We create a data_loader using torch.utils.data.DataLoader() with proper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:54:32.638056Z",
     "start_time": "2020-04-27T18:54:32.627522Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data_loader(root_data_dir,\n",
    "                    data_transform=img_data_transform,\n",
    "                    batch_size=64,\n",
    "                    num_workers=2,\n",
    "                    shuffle=True,\n",
    "                    drop_last=True):\n",
    "    \"\"\"\n",
    "    root_dir is the directory with the images\n",
    "    \"\"\"\n",
    "    face_dataset = ImageDataset(root_data_dir, data_transform)\n",
    "    data_loader = torch.utils.data.DataLoader(face_dataset,\n",
    "                                              batch_size=batch_size,\n",
    "                                              num_workers=num_workers,\n",
    "                                              shuffle=shuffle,\n",
    "                                              drop_last=True)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we use the function above to load the data to data_loader variables which will be called before training our GAN\n",
    "\n",
    "```python\n",
    "train_data_loader = get_data_loader(hyper_parms.data_dir, batch_size=hyper_parms.batch_size, num_workers=5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "##  Network\n",
    "\n",
    "To design our GAN network, we use `nn.Sequential()` to stack several layers and activation functions\n",
    "\n",
    "### First, we create our Discriminator\n",
    "\n",
    "1. We use one Input layer, one Hidden layer and one Output layer. All of them are defined using nn.Linear() with proper input dim and out dim\n",
    "\n",
    "2. We adopt nn.LeakyReLU(0.2) as activation layer for the input and hidden layer. \n",
    "\n",
    "3. We use nn.Sigmoid() activation function for the output layer\n",
    "\n",
    "### Next, we make our Generator \n",
    "\n",
    "1. We need one Input layer, two Hidden layers and one Output layer. All of them are defined using nn.Linear() with proper input and output dimension\n",
    "\n",
    "2. We use nn.ReLU() as activation functions for the Input and Hidden layer. \n",
    "\n",
    "3. We use nn.Tanh() as activation function for the Output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator\n",
    "\n",
    "####  Structure of the Discriminator module as follow:\n",
    "\n",
    "1.\tThe input of the first linear layer is the image size (64), output of the first layer is 256\n",
    "2.\tThen followed by a LeakyReLU layer.\n",
    "3.\tThe input of the second layer is the 256 and output channel is 512\n",
    "4.\tFollowed by the LeakyReLU layer\n",
    "5.\tThe input of the third layer is the 512 and output channel is 512\n",
    "6.\tFollowed by the LeakyReLU layer\n",
    "7.\tThe input of the final layer is the 512 and output channel is 1\n",
    "8.\tThe sigmoid is activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:54:34.145546Z",
     "start_time": "2020-04-27T18:54:34.139556Z"
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_img_size=64, in_img_channels=3, n_gpu=1):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.n_gpu = n_gpu\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            # Input size is input_img_size*input_img_size*3 (img_width, img_height, input_img_channels)\n",
    "            nn.Linear(in_img_size * in_img_size * in_img_channels, 256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, X):\n",
    "        if X.is_cuda and self.n_gpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, X, range(self.n_gpu))\n",
    "        else:\n",
    "            output = self.main(X)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator \n",
    "\n",
    "#### Structure of the Generator module as follow:\n",
    "\n",
    "1.\tThe input of the first linear layer is the latent vector size, output of the first layer is 256\n",
    "2.\tThen followed by a ReLU layer.\n",
    "3.\tThe input of the second layer is the 256 and output channel is 512\n",
    "4.\tFollowed by the ReLU layer\n",
    "5.\tThe input of the third layer is the 512 and output channel is 1024\n",
    "6.\tFollowed by the ReLU layer\n",
    "7.\tThe input of the fourth layer is the 1024 and output channel is 1024\n",
    "8.\tFollowed by the ReLU layer\n",
    "9.\tThe input of the final layer is the 1024 and output channel is the image size.\n",
    "10.\tThe Tanh is activation function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:54:35.489545Z",
     "start_time": "2020-04-27T18:54:35.469602Z"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,\n",
    "                 latent_vector_size,\n",
    "                 in_img_size=64,\n",
    "                 in_img_channels=3,\n",
    "                 n_gpu=1):\n",
    "        super(Generator, self).__init__()\n",
    "        self.n_gpu = n_gpu\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            # laten vector reprs the latent space\n",
    "            nn.Linear(latent_vector_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, in_img_size * in_img_size * in_img_channels),\n",
    "            nn.Tanh())\n",
    "\n",
    "    def forward(self, X):\n",
    "        if X.is_cuda and self.n_gpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, X, range(self.n_gpu))\n",
    "        else:\n",
    "            output = self.main(X)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:54:36.010657Z",
     "start_time": "2020-04-27T18:54:35.991739Z"
    }
   },
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    \"\"\"\n",
    "    GAN Class with fit method that trains the GAN\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 hyper_parameter,\n",
    "                 load_wt=True,\n",
    "                 save_wt=True,\n",
    "                 save_wt_interval=10,\n",
    "                 save_img_interval=50):\n",
    "        self.hp = hyper_parameter\n",
    "        self.G_net = Generator(self.hp.latent_size,\n",
    "                               self.hp.input_img_size).to(device)\n",
    "        self.D_net = Discriminator(self.hp.input_img_size).to(device)\n",
    "        self.D_loss_overtime = []\n",
    "        self.G_loss_overtime = []\n",
    "\n",
    "        if load_wt: self._load_saved_weights()\n",
    "        # Binary Cross Entropy Loss\n",
    "        self.criterion = nn.BCELoss()\n",
    "\n",
    "        # Optimizers\n",
    "        self.G_optimizer = torch.optim.Adam(self.G_net.parameters(),\n",
    "                                            lr=self.hp.learning_rate,\n",
    "                                            betas=(self.hp.beta1, 0.999))\n",
    "        self.D_optimizer = torch.optim.Adam(self.D_net.parameters(),\n",
    "                                            lr=self.hp.learning_rate,\n",
    "                                            betas=(self.hp.beta1, 0.999))\n",
    "\n",
    "    def _load_saved_weights(self):\n",
    "        D_weight_files = glob(self.hp.discriminator_trained_weight_dir +\n",
    "                              '/*.pt')\n",
    "        if D_weight_files:\n",
    "            latest_D_wt = max(D_weight_files, key=os.path.getctime)\n",
    "            print(f\"Loading weight {latest_D_wt} for Discriminator\")\n",
    "            self.D_net.load_state_dict(torch.load(latest_D_wt))\n",
    "            self.D_net.eval()\n",
    "\n",
    "        G_weight_files = glob(self.hp.generator_trained_weight_dir + '/*.pt')\n",
    "        if G_weight_files:\n",
    "            latest_G_wt = max(G_weight_files, key=os.path.getctime)\n",
    "            print(f\"Loading weight {latest_G_wt} for Generator\")\n",
    "            self.G_net.load_state_dict(torch.load(latest_G_wt))\n",
    "            self.G_net.eval()\n",
    "\n",
    "    @staticmethod\n",
    "    def denorm(X):\n",
    "        \"\"\" This is the denorm when norm is done with transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\"\"\"\n",
    "        out = (X + 1) / 2\n",
    "        return out.clamp(0, 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_gan_loss(G_loss, D_loss):\n",
    "        plt.plot(G_loss, label='Generator Loss')\n",
    "        plt.plot(D_loss, label='Discriminator Loss')\n",
    "        plt.title(\"GAN Loss\")\n",
    "        plt.ylabel(\"BCE Loss\")\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_loss(self):\n",
    "        GAN.plot_loss_curve(self.G_loss_overtime, self.D_loss_overtime)\n",
    "\n",
    "    def fit(self, train_data_loader, save_wt=True, save_wt_interval=10):\n",
    "        # Generator uses this noise to generate the images in the dataset for benchmarking\n",
    "        fixed_noise = torch.randn(self.hp.batch_size,\n",
    "                                  self.hp.latent_size,\n",
    "                                  device=device)\n",
    "\n",
    "        for epoch in tqdm(range(self.hp.epochs)):\n",
    "            d_running_loss, g_running_loss = 0, 0\n",
    "\n",
    "            # mini-batch training\n",
    "            for idx, data in enumerate(train_data_loader):\n",
    "                # Exception handling when data is None and image was not able to be read\n",
    "                X_data = data.reshape(\n",
    "                    self.hp.batch_size, -1\n",
    "                )  # set to (64, -1) -1 should be equi to img_sz * img_sz * img_ch\n",
    "                X_data = X_data.to(device)\n",
    "\n",
    "                # real_label = 1, fake_label = 0\n",
    "                real_labels = torch.ones(self.hp.batch_size, 1).to(device)\n",
    "                fake_labels = torch.zeros(self.hp.batch_size, 1).to(device)\n",
    "\n",
    "                ### Train Discriminator which maximizes log(D(x)) + log(1 - D(G(z))) ###\n",
    "                # Using real images\n",
    "                self.D_net.zero_grad()\n",
    "                D_real_output = self.D_net(X_data)  # feedforward\n",
    "                D_real_loss = self.criterion(D_real_output,\n",
    "                                             real_labels)  # cal loss\n",
    "                D_real_loss.backward()\n",
    "\n",
    "                # Using fake images\n",
    "                noise = torch.randn(self.hp.batch_size,\n",
    "                                    self.hp.latent_size,\n",
    "                                    device=device)\n",
    "                G_fake_output = self.G_net(noise)  # feedforward\n",
    "                D_fake_output = self.D_net(G_fake_output.detach())\n",
    "                D_fake_loss = self.criterion(D_fake_output, fake_labels)\n",
    "                D_fake_loss.backward()\n",
    "\n",
    "                D_loss = D_real_loss + D_fake_loss\n",
    "                self.D_optimizer.step()\n",
    "\n",
    "                ### Train Generator which maximizes log(D(G(z))) as Gradient Descent is expensive ###\n",
    "                self.G_net.zero_grad()\n",
    "                G_output = self.D_net(G_fake_output)\n",
    "                G_loss = self.criterion(G_output, real_labels)\n",
    "                G_loss.backward()\n",
    "                self.G_optimizer.step()\n",
    "\n",
    "                d_running_loss += D_loss.item()\n",
    "                g_running_loss += G_loss.item()\n",
    "\n",
    "                if idx % save_img_interval == 0:\n",
    "                    # Real image\n",
    "                    torchvision.utils.save_image(\n",
    "                        data,\n",
    "                        f'{self.hp.output_dir}/{epoch}_{idx}_real_samples.png',\n",
    "                        normalize=True)\n",
    "                    # Generated fake image\n",
    "                    fake_gen = self.G_net(fixed_noise)\n",
    "                    fake_gen = GAN.denorm(\n",
    "                        fake_gen.reshape(self.hp.batch_size, 3,\n",
    "                                         self.hp.input_img_size,\n",
    "                                         self.hp.input_img_size))\n",
    "                    torchvision.utils.save_image(\n",
    "                        fake_gen,\n",
    "                        f'{self.hp.output_dir}/{epoch}_{idx}_fake_samples.png',\n",
    "                        normalize=True)\n",
    "\n",
    "                if idx % 10 == 0:\n",
    "                    print(\n",
    "                        f\"Discriminator Loss at epoch: {epoch}, iter {idx} = {D_loss.item()}\"\n",
    "                    )\n",
    "                    print(\n",
    "                        f\"Generator Loss at epoch: {epoch}, iter {idx} = {G_loss.item()}\"\n",
    "                    )\n",
    "\n",
    "                    d_avg_running_loss = d_running_loss / max(1, idx)\n",
    "                    g_avg_running_loss = g_running_loss / max(1, idx)\n",
    "                    self.D_loss_overtime.append(d_avg_running_loss)\n",
    "                    self.G_loss_overtime.append(g_avg_running_loss)\n",
    "\n",
    "                # Save checkpoint weights\n",
    "                if save_wt and idx % save_wt_interval == 0:\n",
    "                    torch.save(\n",
    "                        self.D_net.state_dict(),\n",
    "                        self.hp.discriminator_trained_weight_dir +\n",
    "                        f'/gnet_epoch_{epoch}_iter_{idx}.pt')\n",
    "                    torch.save(\n",
    "                        self.G_net.state_dict(),\n",
    "                        self.hp.generator_trained_weight_dir +\n",
    "                        f'/gnet_epoch_{epoch}_iter_{idx}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "\n",
    "# GAN TRAIN SECTION\n",
    "\n",
    "First we break down the `GAN.fit(...)` method and run functions one after another\n",
    "________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:58:20.136544Z",
     "start_time": "2020-04-27T18:58:20.127697Z"
    }
   },
   "outputs": [],
   "source": [
    "hyper_parms = HyperParameter(latent_sz=100,\n",
    "                             in_img_size=64,\n",
    "                             in_img_channel=3,\n",
    "                             output_dir=\"../generated_imgs\",\n",
    "                             lr=0.0002,\n",
    "                             beta1=0.5,\n",
    "                             epochs=100,\n",
    "                             batch_sz=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we send the network to the target device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:58:29.095738Z",
     "start_time": "2020-04-27T18:58:28.999126Z"
    }
   },
   "outputs": [],
   "source": [
    "G_net = Generator(hyper_parms.latent_size,\n",
    "                  hyper_parms.input_img_size).to(device)\n",
    "D_net = Discriminator(hyper_parms.input_img_size).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load saved weights for the Generator and the Discriminator if they are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:58:30.555088Z",
     "start_time": "2020-04-27T18:58:30.545557Z"
    }
   },
   "outputs": [],
   "source": [
    "D_weight_files = glob(hyper_parms.discriminator_trained_weight_dir + '/*.pt')\n",
    "if D_weight_files:\n",
    "    latest_D_wt = max(D_weight_files, key=os.path.getctime)\n",
    "    print(f\"Loading weight {latest_D_wt} for Discriminator\")\n",
    "    D_net.load_state_dict(torch.load(latest_D_wt))\n",
    "    D_net.eval()\n",
    "\n",
    "G_weight_files = glob(hyper_parms.generator_trained_weight_dir + '/*.pt')\n",
    "if G_weight_files:\n",
    "    latest_G_wt = max(G_weight_files, key=os.path.getctime)\n",
    "    G_net.load_state_dict(torch.load(latest_G_wt))\n",
    "    print(f\"Loading weight {latest_G_wt} for Generator\")\n",
    "    G_net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Loss function and Optimizer with proper netwrok parameters and learning rates\n",
    "\n",
    "-   Binary Cross Entropy Loss\n",
    "-   ADAM Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:24:41.511510Z",
     "start_time": "2020-04-27T18:24:41.505820Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loss\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Optimizers\n",
    "G_optimizer = torch.optim.Adam(G_net.parameters(),\n",
    "                               lr=hyper_parms.learning_rate,\n",
    "                               betas=(hyper_parms.beta1, 0.999))\n",
    "D_optimizer = torch.optim.Adam(D_net.parameters(),\n",
    "                               lr=hyper_parms.learning_rate,\n",
    "                               betas=(hyper_parms.beta1, 0.999))\n",
    "\n",
    "# Generator uses this noise to generate the images in the dataset for benchmarking\n",
    "fixed_noise = torch.randn(hyper_parms.batch_size,\n",
    "                          hyper_parms.latent_size,\n",
    "                          device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "##  Training\n",
    "\n",
    "### Helper Function\n",
    "\n",
    "1. Denorm function using clamp() api from pytorch https://pytorch.org/docs/stable/torch.html?highlight=clamp#torch.clamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:24:46.656497Z",
     "start_time": "2020-04-27T18:24:46.651775Z"
    }
   },
   "outputs": [],
   "source": [
    "# De-normalization\n",
    "def denorm(x):\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "1. Store the total steps which is equal to the length of data_loader\n",
    "2. for each epoch\n",
    "    <br/> a. for each element index and element in the data loader\n",
    "        i. Reshape the input data to (batch_size，-1) and send to the proper device\n",
    "        ii. Then we create the real and fake labels which are later used as input for the BCE loss using torch.ones(batch_size, 1).to(device) and torch.zeros(batch_size, 1).to(device)\n",
    "        iii. Then we train the descriminator\n",
    "            A. Feedforward and store the predictions of discriminator\n",
    "            B. Compute BCE_Loss using real images and store the loss\n",
    "            C. Random init a latent code z\n",
    "            D. Feedforward and store the predictions of generator\n",
    "            E. Feed the predictions to the descriminator and store the prediction\n",
    "            F. Compute BCELoss using fake images and store the loss\n",
    "            G. Backprop the losses after reseting the optimizer gradients\n",
    "        iv. Then we train the generator\n",
    "            A. using torch.randn(batch_size, latent_size).to(device) to init a z\n",
    "            B. Feedforward and store the predictions of generator\n",
    "            C. feed the predictions to the descriminator and sotre the prediction\n",
    "            D. compute BCE_Loss using real images and store the loss\n",
    "            F. perform the backprop using losses after that reset the gradient of optimizer.\n",
    "        v. After some epochs, we print logs with proper info\n",
    "    <br/> b. We store all real image with shape (images.size(0), 1, 28, 28) inoder for the further comparision only once\n",
    "    <br/> c. We save the fake image with image shape (images.size(0), 1, 28, 28) and denorm() function \n",
    "3. Save the model checkpoints using torch.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:24:48.885409Z",
     "start_time": "2020-04-27T18:24:48.879640Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latent_size: 100\n",
       "learning_rate: 0.0002\n",
       "beta1: 0.5\n",
       "input_img_size: 64\n",
       "input_img_channel: 3\n",
       "epochs: 100\n",
       "batch_size: 64\n",
       "data_dir: ../data/img_align_celeba\n",
       "output_dir: ../generated_imgs\n",
       "discriminator_trained_weight_dir: ../discriminator_trained_weights\n",
       "generator_trained_weight_dir: ../generator_trained_weights"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:25:35.591827Z",
     "start_time": "2020-04-27T18:25:18.753947Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 0, iter 0 = 1.162583589553833\n",
      "Generator Loss at epoch: 0, iter 0 = 2.3888092041015625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-6a6930e76be4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     99\u001b[0m             torch.save(\n\u001b[1;32m    100\u001b[0m                 \u001b[0mG_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 hyper_parms.generator_trained_weight_dir + f'/gnet_{epoch}.pt')\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/new_pytorch/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \"\"\"\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/new_pytorch/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DEBUG = False\n",
    "D_loss_overtime, G_loss_overtime = [], []\n",
    "save_weights = True\n",
    "save_weight_interval = 10\n",
    "save_img_interval = 50\n",
    "data_loader = get_data_loader(\"../mini_data/\")\n",
    "\n",
    "for epoch in tqdm(range(hyper_parms.epochs)):\n",
    "    d_running_loss, g_running_loss = 0, 0\n",
    "\n",
    "    # mini-batch training\n",
    "    for idx, data in enumerate(data_loader):\n",
    "        # Exception handling when data is None and image was not able to be read\n",
    "        # set to (64, -1) -1 should be equi to img_sz * img_sz * img_ch\n",
    "        X_data = data.reshape(hyper_parms.batch_size, -1)\n",
    "        X_data = X_data.to(device)\n",
    "\n",
    "        # real_label = 1, fake_label = 0\n",
    "        real_labels = torch.ones(hyper_parms.batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(hyper_parms.batch_size, 1).to(device)\n",
    "\n",
    "        ### Train Discriminator which maximizes log(D(x)) + log(1 - D(G(z))) ###\n",
    "        # Using real images\n",
    "        D_net.zero_grad()\n",
    "        if DEBUG: print(\"X_data.shape\", X_data.shape)\n",
    "        D_real_output = D_net(X_data)  # feedforward\n",
    "        if DEBUG:\n",
    "            print(\"D_real_output.shape\", D_real_output.shape,\n",
    "                  \"real_labels.shape\", real_labels.shape)\n",
    "        D_real_loss = criterion(D_real_output, real_labels)  # cal loss\n",
    "        D_real_loss.backward()\n",
    "\n",
    "        # Using fake images\n",
    "        noise = torch.randn(hyper_parms.batch_size,\n",
    "                            hyper_parms.latent_size,\n",
    "                            device=device)\n",
    "        G_fake_output = G_net(noise)  # feedforward\n",
    "        D_fake_output = D_net(G_fake_output.detach())\n",
    "        if DEBUG:\n",
    "            print(\"G_fake_output.shape\", D_fake_output.shape,\n",
    "                  \"fake_labels.shape\", fake_labels.shape)\n",
    "        D_fake_loss = criterion(D_fake_output, fake_labels)\n",
    "        D_fake_loss.backward()\n",
    "\n",
    "        D_loss = D_real_loss + D_fake_loss\n",
    "        D_optimizer.step()\n",
    "\n",
    "        ### Train Generator which maximizes log(D(G(z))) as Gradient Descent is expensive ###\n",
    "        G_net.zero_grad()\n",
    "        G_output = D_net(G_fake_output)\n",
    "        if DEBUG:\n",
    "            print(\"G_output.shape\", G_output.shape, \"real_labels.shape\",\n",
    "                  real_labels.shape)\n",
    "        G_loss = criterion(G_output, real_labels)\n",
    "        G_loss.backward()\n",
    "        G_optimizer.step()\n",
    "\n",
    "        d_running_loss += D_loss.item()\n",
    "        g_running_loss += G_loss.item()\n",
    "\n",
    "        if idx % save_img_interval == 0:\n",
    "            # Real image\n",
    "            if DEBUG: print(\"Original Image Shape\", data.shape)\n",
    "            torchvision.utils.save_image(\n",
    "                data,\n",
    "                f'{hyper_parms.output_dir}/{epoch}_{idx}_real_samples.png',\n",
    "                normalize=True)\n",
    "            # Generated fake image\n",
    "            fake_gen = G_net(fixed_noise)\n",
    "            fake_gen = denorm(\n",
    "                fake_gen.reshape(hyper_parms.batch_size, 3,\n",
    "                                 hyper_parms.input_img_size,\n",
    "                                 hyper_parms.input_img_size))\n",
    "            if DEBUG: print(\"Fake Image Shape\", fake_gen.shape)\n",
    "            torchvision.utils.save_image(\n",
    "                fake_gen,\n",
    "                f'{hyper_parms.output_dir}/{epoch}_{idx}_fake_samples.png',\n",
    "                normalize=True)\n",
    "\n",
    "        if idx % 10 == 0:\n",
    "            print(\n",
    "                f\"Discriminator Loss at epoch: {epoch}, iter {idx} = {D_loss.item()}\"\n",
    "            )\n",
    "            print(\n",
    "                f\"Generator Loss at epoch: {epoch}, iter {idx} = {G_loss.item()}\"\n",
    "            )\n",
    "\n",
    "            d_avg_running_loss = d_running_loss / max(1, idx)\n",
    "            g_avg_running_loss = g_running_loss / max(1, idx)\n",
    "            D_loss_overtime.append(d_avg_running_loss)\n",
    "            G_loss_overtime.append(g_avg_running_loss)\n",
    "\n",
    "        # Save checkpoint weights\n",
    "        if save_weights and epoch % save_weight_interval == 0:  # Save model weights after every 10 epochs\n",
    "            torch.save(\n",
    "                D_net.state_dict(),\n",
    "                hyper_parms.discriminator_trained_weight_dir +\n",
    "                f'/gnet_{epoch}.pt')\n",
    "            torch.save(\n",
    "                G_net.state_dict(),\n",
    "                hyper_parms.generator_trained_weight_dir + f'/gnet_{epoch}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:26:08.963634Z",
     "start_time": "2020-04-27T18:26:08.879249Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "GAN.plot_gan_loss(G_loss_overtime, D_loss_overtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our model on the small dataset with our GAN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weight ../discriminator_trained_weights/gnet_90.pt for Discriminator\n",
      "Loading weight ../generator_trained_weights/gnet_90.pt for Generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 0, iter 0 = 0.2714161276817322\n",
      "Generator Loss at epoch: 0, iter 0 = 3.154052734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 1/100 [00:03<06:14,  3.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 1, iter 0 = 0.015406203456223011\n",
      "Generator Loss at epoch: 1, iter 0 = 5.4661688804626465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 2/100 [00:08<06:23,  3.91s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 2, iter 0 = 1.5463693141937256\n",
      "Generator Loss at epoch: 2, iter 0 = 2.5806195735931396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 3/100 [00:12<06:39,  4.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 3, iter 0 = 0.635512113571167\n",
      "Generator Loss at epoch: 3, iter 0 = 5.190150260925293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 4/100 [00:16<06:34,  4.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 4, iter 0 = 0.23574446141719818\n",
      "Generator Loss at epoch: 4, iter 0 = 4.377322196960449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 5/100 [00:20<06:29,  4.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 5, iter 0 = 0.33431634306907654\n",
      "Generator Loss at epoch: 5, iter 0 = 4.95803165435791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|▌         | 6/100 [00:24<06:23,  4.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 6, iter 0 = 0.48373985290527344\n",
      "Generator Loss at epoch: 6, iter 0 = 4.7859086990356445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 7/100 [00:28<06:22,  4.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 7, iter 0 = 0.1716458946466446\n",
      "Generator Loss at epoch: 7, iter 0 = 5.606947898864746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 8/100 [00:32<06:09,  4.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 8, iter 0 = 1.2877533435821533\n",
      "Generator Loss at epoch: 8, iter 0 = 5.887701511383057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|▉         | 9/100 [00:36<06:07,  4.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 9, iter 0 = 0.12768962979316711\n",
      "Generator Loss at epoch: 9, iter 0 = 5.68284797668457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 10/100 [00:41<06:16,  4.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 10, iter 0 = 0.33509188890457153\n",
      "Generator Loss at epoch: 10, iter 0 = 4.637724876403809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█         | 11/100 [00:45<06:11,  4.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 11, iter 0 = 0.12786251306533813\n",
      "Generator Loss at epoch: 11, iter 0 = 4.199770927429199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▏        | 12/100 [00:49<06:04,  4.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 12, iter 0 = 0.35080885887145996\n",
      "Generator Loss at epoch: 12, iter 0 = 5.911106586456299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|█▎        | 13/100 [00:53<05:56,  4.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 13, iter 0 = 1.0398783683776855\n",
      "Generator Loss at epoch: 13, iter 0 = 4.442173957824707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 14/100 [00:57<05:51,  4.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 14, iter 0 = 0.10141082108020782\n",
      "Generator Loss at epoch: 14, iter 0 = 4.708858966827393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 15/100 [01:01<05:43,  4.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 15, iter 0 = 0.8163585662841797\n",
      "Generator Loss at epoch: 15, iter 0 = 4.141700744628906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▌        | 16/100 [01:05<05:39,  4.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 16, iter 0 = 0.7840877771377563\n",
      "Generator Loss at epoch: 16, iter 0 = 2.2453036308288574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 17/100 [01:09<05:35,  4.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 17, iter 0 = 1.2453644275665283\n",
      "Generator Loss at epoch: 17, iter 0 = 6.763755798339844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|█▊        | 18/100 [01:13<05:30,  4.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 18, iter 0 = 0.23123270273208618\n",
      "Generator Loss at epoch: 18, iter 0 = 4.716520309448242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|█▉        | 19/100 [01:18<05:43,  4.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 19, iter 0 = 0.8381882905960083\n",
      "Generator Loss at epoch: 19, iter 0 = 6.20436954498291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 20/100 [01:22<05:32,  4.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 20, iter 0 = 0.279288113117218\n",
      "Generator Loss at epoch: 20, iter 0 = 4.572755813598633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 21%|██        | 21/100 [01:26<05:25,  4.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 21, iter 0 = 0.43881821632385254\n",
      "Generator Loss at epoch: 21, iter 0 = 3.845395803451538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 22/100 [01:30<05:19,  4.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 22, iter 0 = 0.9653716087341309\n",
      "Generator Loss at epoch: 22, iter 0 = 3.6064019203186035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 23%|██▎       | 23/100 [01:34<05:12,  4.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 23, iter 0 = 0.3766833543777466\n",
      "Generator Loss at epoch: 23, iter 0 = 3.923429489135742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▍       | 24/100 [01:38<05:08,  4.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 24, iter 0 = 0.7685054540634155\n",
      "Generator Loss at epoch: 24, iter 0 = 4.206501483917236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 25/100 [01:42<05:12,  4.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 25, iter 0 = 1.8823782205581665\n",
      "Generator Loss at epoch: 25, iter 0 = 2.129472017288208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▌       | 26/100 [01:46<05:02,  4.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 26, iter 0 = 0.5655657052993774\n",
      "Generator Loss at epoch: 26, iter 0 = 5.486574172973633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|██▋       | 27/100 [01:50<04:53,  4.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 27, iter 0 = 0.5504202842712402\n",
      "Generator Loss at epoch: 27, iter 0 = 2.9782865047454834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 28%|██▊       | 28/100 [01:54<04:47,  4.00s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 28, iter 0 = 0.6909208297729492\n",
      "Generator Loss at epoch: 28, iter 0 = 4.285668849945068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▉       | 29/100 [01:58<04:43,  3.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 29, iter 0 = 1.6356558799743652\n",
      "Generator Loss at epoch: 29, iter 0 = 5.386567115783691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 30/100 [02:02<04:40,  4.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 30, iter 0 = 0.3878919780254364\n",
      "Generator Loss at epoch: 30, iter 0 = 2.798490524291992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|███       | 31/100 [02:06<04:38,  4.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 31, iter 0 = 0.7988347411155701\n",
      "Generator Loss at epoch: 31, iter 0 = 6.050369739532471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 32%|███▏      | 32/100 [02:11<04:39,  4.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 32, iter 0 = 1.2193677425384521\n",
      "Generator Loss at epoch: 32, iter 0 = 4.013647079467773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 33/100 [02:15<04:33,  4.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 33, iter 0 = 1.5567262172698975\n",
      "Generator Loss at epoch: 33, iter 0 = 8.268945693969727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 34%|███▍      | 34/100 [02:19<04:36,  4.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 34, iter 0 = 0.7193228006362915\n",
      "Generator Loss at epoch: 34, iter 0 = 4.033636569976807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 35/100 [02:23<04:32,  4.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 35, iter 0 = 0.9660996198654175\n",
      "Generator Loss at epoch: 35, iter 0 = 4.159087657928467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 36%|███▌      | 36/100 [02:27<04:26,  4.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 36, iter 0 = 0.15521903336048126\n",
      "Generator Loss at epoch: 36, iter 0 = 5.116477966308594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 37%|███▋      | 37/100 [02:31<04:21,  4.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 37, iter 0 = 1.6679365634918213\n",
      "Generator Loss at epoch: 37, iter 0 = 3.4641757011413574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 38%|███▊      | 38/100 [02:36<04:16,  4.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 38, iter 0 = 0.5359369516372681\n",
      "Generator Loss at epoch: 38, iter 0 = 2.378218650817871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 39%|███▉      | 39/100 [02:40<04:20,  4.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 39, iter 0 = 0.8137494921684265\n",
      "Generator Loss at epoch: 39, iter 0 = 0.8343470096588135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 40/100 [02:44<04:09,  4.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 40, iter 0 = 0.7417871356010437\n",
      "Generator Loss at epoch: 40, iter 0 = 2.6095242500305176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 41%|████      | 41/100 [02:48<04:01,  4.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 41, iter 0 = 0.8104246854782104\n",
      "Generator Loss at epoch: 41, iter 0 = 3.7072958946228027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 42%|████▏     | 42/100 [02:52<03:56,  4.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 42, iter 0 = 1.0738104581832886\n",
      "Generator Loss at epoch: 42, iter 0 = 2.731499671936035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 43%|████▎     | 43/100 [02:56<03:50,  4.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 43, iter 0 = 0.7049455642700195\n",
      "Generator Loss at epoch: 43, iter 0 = 1.9696624279022217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 44%|████▍     | 44/100 [03:00<03:47,  4.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 44, iter 0 = 0.502007246017456\n",
      "Generator Loss at epoch: 44, iter 0 = 3.1097941398620605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 45/100 [03:04<03:43,  4.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 45, iter 0 = 0.5661680102348328\n",
      "Generator Loss at epoch: 45, iter 0 = 5.331399440765381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 46%|████▌     | 46/100 [03:08<03:36,  4.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 46, iter 0 = 1.2750662565231323\n",
      "Generator Loss at epoch: 46, iter 0 = 5.387781143188477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 47%|████▋     | 47/100 [03:12<03:31,  3.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 47, iter 0 = 0.3253340423107147\n",
      "Generator Loss at epoch: 47, iter 0 = 3.463900566101074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 48%|████▊     | 48/100 [03:16<03:26,  3.98s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 48, iter 0 = 0.19513103365898132\n",
      "Generator Loss at epoch: 48, iter 0 = 4.87217903137207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 49%|████▉     | 49/100 [03:20<03:24,  4.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 49, iter 0 = 1.3437635898590088\n",
      "Generator Loss at epoch: 49, iter 0 = 5.052617073059082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 50/100 [03:25<03:33,  4.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 50, iter 0 = 0.6301249265670776\n",
      "Generator Loss at epoch: 50, iter 0 = 2.4525208473205566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 51%|█████     | 51/100 [03:29<03:23,  4.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 51, iter 0 = 0.8892245292663574\n",
      "Generator Loss at epoch: 51, iter 0 = 6.157757759094238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 52%|█████▏    | 52/100 [03:33<03:15,  4.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 52, iter 0 = 1.491617202758789\n",
      "Generator Loss at epoch: 52, iter 0 = 4.95188045501709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 53%|█████▎    | 53/100 [03:37<03:10,  4.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 53, iter 0 = 0.37582558393478394\n",
      "Generator Loss at epoch: 53, iter 0 = 4.697523593902588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 54%|█████▍    | 54/100 [03:41<03:16,  4.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 54, iter 0 = 0.7676321268081665\n",
      "Generator Loss at epoch: 54, iter 0 = 3.8884549140930176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 55/100 [03:45<03:08,  4.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 55, iter 0 = 1.2405548095703125\n",
      "Generator Loss at epoch: 55, iter 0 = 3.278095006942749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 56%|█████▌    | 56/100 [03:50<03:03,  4.17s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 56, iter 0 = 0.9014707803726196\n",
      "Generator Loss at epoch: 56, iter 0 = 1.0522280931472778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 57%|█████▋    | 57/100 [03:54<02:59,  4.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 57, iter 0 = 1.3510956764221191\n",
      "Generator Loss at epoch: 57, iter 0 = 5.0505523681640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 58%|█████▊    | 58/100 [03:58<02:52,  4.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 58, iter 0 = 0.9851689338684082\n",
      "Generator Loss at epoch: 58, iter 0 = 4.486946105957031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 59%|█████▉    | 59/100 [04:02<02:45,  4.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 59, iter 0 = 1.0309202671051025\n",
      "Generator Loss at epoch: 59, iter 0 = 3.7123680114746094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 60/100 [04:06<02:41,  4.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 60, iter 0 = 0.48590540885925293\n",
      "Generator Loss at epoch: 60, iter 0 = 3.8393402099609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 61%|██████    | 61/100 [04:09<02:35,  3.98s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 61, iter 0 = 0.5274093747138977\n",
      "Generator Loss at epoch: 61, iter 0 = 5.24628210067749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 62%|██████▏   | 62/100 [04:14<02:33,  4.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 62, iter 0 = 0.4979315996170044\n",
      "Generator Loss at epoch: 62, iter 0 = 4.24357271194458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 63%|██████▎   | 63/100 [04:18<02:29,  4.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 63, iter 0 = 1.8246612548828125\n",
      "Generator Loss at epoch: 63, iter 0 = 0.7841494083404541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 64%|██████▍   | 64/100 [04:22<02:24,  4.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 64, iter 0 = 1.1675673723220825\n",
      "Generator Loss at epoch: 64, iter 0 = 6.195089340209961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 65/100 [04:26<02:22,  4.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 65, iter 0 = 0.5940215587615967\n",
      "Generator Loss at epoch: 65, iter 0 = 2.1985726356506348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 66%|██████▌   | 66/100 [04:30<02:21,  4.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 66, iter 0 = 0.3588326573371887\n",
      "Generator Loss at epoch: 66, iter 0 = 4.572836875915527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 67/100 [04:34<02:15,  4.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 67, iter 0 = 0.10403239727020264\n",
      "Generator Loss at epoch: 67, iter 0 = 4.7737321853637695\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-86827a81dbfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msmall_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../mini_data/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmall_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-ccfc1d32deac>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data_loader, save_wt, save_wt_interval)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;31m# mini-batch training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0;31m# Exception handling when data is None and image was not able to be read\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mX_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# set to (64, -1) -1 should be equi to img_sz * img_sz * img_ch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/sss_pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/sss_pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/sss_pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/sss_pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/sss_pytorch/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/sss_pytorch/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/sss_pytorch/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/sss_pytorch/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/sss_pytorch/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hp1 = HyperParameter(latent_sz=100, in_img_size=64, in_img_channel=3, \n",
    "                     output_dir=\"../generated_imgs\",\n",
    "                     lr=0.0002, beta1=0.5, epochs=100, batch_sz=64)\n",
    "small_dataset = get_data_loader(\"../mini_data/\")\n",
    "g1 = GAN(hp1)\n",
    "g1.fit(small_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting its loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:25:35.594071Z",
     "start_time": "2020-04-27T18:25:32.631Z"
    }
   },
   "outputs": [],
   "source": [
    "g1.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our model on the full dataset with our GAN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weight ../discriminator_trained_weights/gnet_epoch_67_iter_0.pt for Discriminator\n",
      "Loading weight ../generator_trained_weights/gnet_epoch_67_iter_0.pt for Generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 0, iter 0 = 0.26854756474494934\n",
      "Generator Loss at epoch: 0, iter 0 = 4.506418228149414\n",
      "Discriminator Loss at epoch: 0, iter 10 = 0.08776470273733139\n",
      "Generator Loss at epoch: 0, iter 10 = 4.87294864654541\n",
      "Discriminator Loss at epoch: 0, iter 20 = 0.10007470846176147\n",
      "Generator Loss at epoch: 0, iter 20 = 4.455535411834717\n",
      "Discriminator Loss at epoch: 0, iter 30 = 0.14859245717525482\n",
      "Generator Loss at epoch: 0, iter 30 = 4.926784515380859\n",
      "Discriminator Loss at epoch: 0, iter 40 = 0.20604735612869263\n",
      "Generator Loss at epoch: 0, iter 40 = 5.940629959106445\n",
      "Discriminator Loss at epoch: 0, iter 50 = 0.22873365879058838\n",
      "Generator Loss at epoch: 0, iter 50 = 3.4873294830322266\n",
      "Discriminator Loss at epoch: 0, iter 60 = 0.24626193940639496\n",
      "Generator Loss at epoch: 0, iter 60 = 4.887941360473633\n",
      "Discriminator Loss at epoch: 0, iter 70 = 0.23680070042610168\n",
      "Generator Loss at epoch: 0, iter 70 = 5.0799078941345215\n",
      "Discriminator Loss at epoch: 0, iter 80 = 1.6336243152618408\n",
      "Generator Loss at epoch: 0, iter 80 = 3.6133973598480225\n",
      "Discriminator Loss at epoch: 0, iter 90 = 0.22466063499450684\n",
      "Generator Loss at epoch: 0, iter 90 = 4.030560493469238\n",
      "Discriminator Loss at epoch: 0, iter 100 = 0.1188485249876976\n",
      "Generator Loss at epoch: 0, iter 100 = 5.364528656005859\n",
      "Discriminator Loss at epoch: 0, iter 110 = 0.1820766031742096\n",
      "Generator Loss at epoch: 0, iter 110 = 5.232792854309082\n",
      "Discriminator Loss at epoch: 0, iter 120 = 0.4546359181404114\n",
      "Generator Loss at epoch: 0, iter 120 = 3.9753382205963135\n",
      "Discriminator Loss at epoch: 0, iter 130 = 0.4039352834224701\n",
      "Generator Loss at epoch: 0, iter 130 = 3.1653389930725098\n",
      "Discriminator Loss at epoch: 0, iter 140 = 0.4836421012878418\n",
      "Generator Loss at epoch: 0, iter 140 = 7.113472938537598\n",
      "Discriminator Loss at epoch: 0, iter 150 = 1.345031976699829\n",
      "Generator Loss at epoch: 0, iter 150 = 5.569055557250977\n",
      "Discriminator Loss at epoch: 0, iter 160 = 0.15346476435661316\n",
      "Generator Loss at epoch: 0, iter 160 = 2.6348488330841064\n",
      "Discriminator Loss at epoch: 0, iter 170 = 1.1272404193878174\n",
      "Generator Loss at epoch: 0, iter 170 = 7.280593395233154\n",
      "Discriminator Loss at epoch: 0, iter 180 = 1.2289365530014038\n",
      "Generator Loss at epoch: 0, iter 180 = 5.312110900878906\n",
      "Discriminator Loss at epoch: 0, iter 190 = 1.068556785583496\n",
      "Generator Loss at epoch: 0, iter 190 = 5.062741279602051\n",
      "Discriminator Loss at epoch: 0, iter 200 = 0.4418761134147644\n",
      "Generator Loss at epoch: 0, iter 200 = 4.831268310546875\n",
      "Discriminator Loss at epoch: 0, iter 210 = 0.5716136693954468\n",
      "Generator Loss at epoch: 0, iter 210 = 3.724233865737915\n",
      "Discriminator Loss at epoch: 0, iter 220 = 0.4716079533100128\n",
      "Generator Loss at epoch: 0, iter 220 = 3.412000894546509\n",
      "Discriminator Loss at epoch: 0, iter 230 = 1.1631147861480713\n",
      "Generator Loss at epoch: 0, iter 230 = 8.168533325195312\n",
      "Discriminator Loss at epoch: 0, iter 240 = 0.4572069048881531\n",
      "Generator Loss at epoch: 0, iter 240 = 3.7789089679718018\n",
      "Discriminator Loss at epoch: 0, iter 250 = 0.9376342296600342\n",
      "Generator Loss at epoch: 0, iter 250 = 3.5066325664520264\n",
      "Discriminator Loss at epoch: 0, iter 260 = 3.728175640106201\n",
      "Generator Loss at epoch: 0, iter 260 = 7.988401889801025\n",
      "Discriminator Loss at epoch: 0, iter 270 = 0.7694731950759888\n",
      "Generator Loss at epoch: 0, iter 270 = 8.058357238769531\n",
      "Discriminator Loss at epoch: 0, iter 280 = 1.2121816873550415\n",
      "Generator Loss at epoch: 0, iter 280 = 6.901094436645508\n",
      "Discriminator Loss at epoch: 0, iter 290 = 0.31853488087654114\n",
      "Generator Loss at epoch: 0, iter 290 = 4.005601406097412\n",
      "Discriminator Loss at epoch: 0, iter 300 = 0.18829694390296936\n",
      "Generator Loss at epoch: 0, iter 300 = 6.271924018859863\n",
      "Discriminator Loss at epoch: 0, iter 310 = 2.180114984512329\n",
      "Generator Loss at epoch: 0, iter 310 = 3.955188751220703\n",
      "Discriminator Loss at epoch: 0, iter 320 = 1.5578559637069702\n",
      "Generator Loss at epoch: 0, iter 320 = 2.9282331466674805\n",
      "Discriminator Loss at epoch: 0, iter 330 = 0.24191290140151978\n",
      "Generator Loss at epoch: 0, iter 330 = 4.0674824714660645\n",
      "Discriminator Loss at epoch: 0, iter 340 = 1.4295490980148315\n",
      "Generator Loss at epoch: 0, iter 340 = 3.530252456665039\n",
      "Discriminator Loss at epoch: 0, iter 350 = 1.7291314601898193\n",
      "Generator Loss at epoch: 0, iter 350 = 5.938752174377441\n",
      "Discriminator Loss at epoch: 0, iter 360 = 1.1199345588684082\n",
      "Generator Loss at epoch: 0, iter 360 = 1.8930424451828003\n",
      "Discriminator Loss at epoch: 0, iter 370 = 1.4380922317504883\n",
      "Generator Loss at epoch: 0, iter 370 = 3.614708423614502\n",
      "Discriminator Loss at epoch: 0, iter 380 = 1.673056721687317\n",
      "Generator Loss at epoch: 0, iter 380 = 1.4650287628173828\n",
      "Discriminator Loss at epoch: 0, iter 390 = 0.21345816552639008\n",
      "Generator Loss at epoch: 0, iter 390 = 4.001626014709473\n",
      "Discriminator Loss at epoch: 0, iter 400 = 0.33428889513015747\n",
      "Generator Loss at epoch: 0, iter 400 = 7.190246105194092\n",
      "Discriminator Loss at epoch: 0, iter 410 = 0.9919068813323975\n",
      "Generator Loss at epoch: 0, iter 410 = 3.0107998847961426\n",
      "Discriminator Loss at epoch: 0, iter 420 = 1.5322928428649902\n",
      "Generator Loss at epoch: 0, iter 420 = 3.5943708419799805\n",
      "Discriminator Loss at epoch: 0, iter 430 = 1.5265843868255615\n",
      "Generator Loss at epoch: 0, iter 430 = 5.19663143157959\n",
      "Discriminator Loss at epoch: 0, iter 440 = 0.13400068879127502\n",
      "Generator Loss at epoch: 0, iter 440 = 4.833687782287598\n",
      "Discriminator Loss at epoch: 0, iter 450 = 0.29065126180648804\n",
      "Generator Loss at epoch: 0, iter 450 = 5.091846942901611\n",
      "Discriminator Loss at epoch: 0, iter 460 = 2.3502495288848877\n",
      "Generator Loss at epoch: 0, iter 460 = 4.247617721557617\n",
      "Discriminator Loss at epoch: 0, iter 470 = 1.3210875988006592\n",
      "Generator Loss at epoch: 0, iter 470 = 4.942770957946777\n",
      "Discriminator Loss at epoch: 0, iter 480 = 0.6722894310951233\n",
      "Generator Loss at epoch: 0, iter 480 = 3.4005937576293945\n",
      "Discriminator Loss at epoch: 0, iter 490 = 1.1033649444580078\n",
      "Generator Loss at epoch: 0, iter 490 = 3.662372350692749\n",
      "Discriminator Loss at epoch: 0, iter 500 = 1.0123958587646484\n",
      "Generator Loss at epoch: 0, iter 500 = 6.9543256759643555\n",
      "Discriminator Loss at epoch: 0, iter 510 = 0.8310086727142334\n",
      "Generator Loss at epoch: 0, iter 510 = 3.2278661727905273\n",
      "Discriminator Loss at epoch: 0, iter 520 = 0.4128930866718292\n",
      "Generator Loss at epoch: 0, iter 520 = 4.483839511871338\n",
      "Discriminator Loss at epoch: 0, iter 530 = 1.2133100032806396\n",
      "Generator Loss at epoch: 0, iter 530 = 7.547613143920898\n",
      "Discriminator Loss at epoch: 0, iter 540 = 0.7507151365280151\n",
      "Generator Loss at epoch: 0, iter 540 = 3.816236734390259\n",
      "Discriminator Loss at epoch: 0, iter 550 = 0.2828449010848999\n",
      "Generator Loss at epoch: 0, iter 550 = 4.270859718322754\n",
      "Discriminator Loss at epoch: 0, iter 560 = 2.1892385482788086\n",
      "Generator Loss at epoch: 0, iter 560 = 4.649263381958008\n",
      "Discriminator Loss at epoch: 0, iter 570 = 1.6182940006256104\n",
      "Generator Loss at epoch: 0, iter 570 = 4.252639293670654\n",
      "Discriminator Loss at epoch: 0, iter 580 = 0.150863379240036\n",
      "Generator Loss at epoch: 0, iter 580 = 3.6307287216186523\n",
      "Discriminator Loss at epoch: 0, iter 590 = 0.4813653230667114\n",
      "Generator Loss at epoch: 0, iter 590 = 5.010430812835693\n",
      "Discriminator Loss at epoch: 0, iter 600 = 0.615818440914154\n",
      "Generator Loss at epoch: 0, iter 600 = 3.727889060974121\n",
      "Discriminator Loss at epoch: 0, iter 610 = 0.37418240308761597\n",
      "Generator Loss at epoch: 0, iter 610 = 2.8114326000213623\n",
      "Discriminator Loss at epoch: 0, iter 620 = 0.972793698310852\n",
      "Generator Loss at epoch: 0, iter 620 = 3.442560911178589\n",
      "Discriminator Loss at epoch: 0, iter 630 = 0.47307145595550537\n",
      "Generator Loss at epoch: 0, iter 630 = 4.925957679748535\n",
      "Discriminator Loss at epoch: 0, iter 640 = 0.40090012550354004\n",
      "Generator Loss at epoch: 0, iter 640 = 3.1028409004211426\n",
      "Discriminator Loss at epoch: 0, iter 650 = 1.3122179508209229\n",
      "Generator Loss at epoch: 0, iter 650 = 3.408867835998535\n",
      "Discriminator Loss at epoch: 0, iter 660 = 0.8646790981292725\n",
      "Generator Loss at epoch: 0, iter 660 = 5.832093238830566\n",
      "Discriminator Loss at epoch: 0, iter 670 = 0.5720277428627014\n",
      "Generator Loss at epoch: 0, iter 670 = 3.8766236305236816\n",
      "Discriminator Loss at epoch: 0, iter 680 = 0.935327410697937\n",
      "Generator Loss at epoch: 0, iter 680 = 3.254412889480591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 0, iter 690 = 1.2165673971176147\n",
      "Generator Loss at epoch: 0, iter 690 = 5.984757423400879\n",
      "Discriminator Loss at epoch: 0, iter 700 = 0.3477962017059326\n",
      "Generator Loss at epoch: 0, iter 700 = 3.1772093772888184\n",
      "Discriminator Loss at epoch: 0, iter 710 = 0.4129464626312256\n",
      "Generator Loss at epoch: 0, iter 710 = 3.389273166656494\n",
      "Discriminator Loss at epoch: 0, iter 720 = 0.7773125171661377\n",
      "Generator Loss at epoch: 0, iter 720 = 6.879718780517578\n",
      "Discriminator Loss at epoch: 0, iter 730 = 1.197854995727539\n",
      "Generator Loss at epoch: 0, iter 730 = 4.16965389251709\n",
      "Discriminator Loss at epoch: 0, iter 740 = 0.8086649179458618\n",
      "Generator Loss at epoch: 0, iter 740 = 2.2169837951660156\n",
      "Discriminator Loss at epoch: 0, iter 750 = 0.4730989336967468\n",
      "Generator Loss at epoch: 0, iter 750 = 4.288393974304199\n",
      "Discriminator Loss at epoch: 0, iter 760 = 0.6782304048538208\n",
      "Generator Loss at epoch: 0, iter 760 = 4.435580253601074\n",
      "Discriminator Loss at epoch: 0, iter 770 = 2.4411978721618652\n",
      "Generator Loss at epoch: 0, iter 770 = 3.6962532997131348\n",
      "Discriminator Loss at epoch: 0, iter 780 = 0.5167614221572876\n",
      "Generator Loss at epoch: 0, iter 780 = 2.6399049758911133\n",
      "Discriminator Loss at epoch: 0, iter 790 = 0.2790798544883728\n",
      "Generator Loss at epoch: 0, iter 790 = 3.7606723308563232\n",
      "Discriminator Loss at epoch: 0, iter 800 = 1.4311102628707886\n",
      "Generator Loss at epoch: 0, iter 800 = 9.14539909362793\n",
      "Discriminator Loss at epoch: 0, iter 810 = 1.8129630088806152\n",
      "Generator Loss at epoch: 0, iter 810 = 2.9518003463745117\n",
      "Discriminator Loss at epoch: 0, iter 820 = 0.46281617879867554\n",
      "Generator Loss at epoch: 0, iter 820 = 2.733139991760254\n",
      "Discriminator Loss at epoch: 0, iter 830 = 0.33453553915023804\n",
      "Generator Loss at epoch: 0, iter 830 = 2.2644340991973877\n",
      "Discriminator Loss at epoch: 0, iter 840 = 0.7839471697807312\n",
      "Generator Loss at epoch: 0, iter 840 = 3.4226412773132324\n",
      "Discriminator Loss at epoch: 0, iter 850 = 0.5940343737602234\n",
      "Generator Loss at epoch: 0, iter 850 = 5.0725250244140625\n",
      "Discriminator Loss at epoch: 0, iter 860 = 0.9045149087905884\n",
      "Generator Loss at epoch: 0, iter 860 = 2.9839015007019043\n",
      "Discriminator Loss at epoch: 0, iter 870 = 0.35854652523994446\n",
      "Generator Loss at epoch: 0, iter 870 = 3.1331770420074463\n",
      "Discriminator Loss at epoch: 0, iter 880 = 0.08017361909151077\n",
      "Generator Loss at epoch: 0, iter 880 = 4.374626159667969\n",
      "Discriminator Loss at epoch: 0, iter 890 = 0.558521568775177\n",
      "Generator Loss at epoch: 0, iter 890 = 3.7489304542541504\n",
      "Discriminator Loss at epoch: 0, iter 900 = 3.0539984703063965\n",
      "Generator Loss at epoch: 0, iter 900 = 6.664524078369141\n",
      "Discriminator Loss at epoch: 0, iter 910 = 1.0512129068374634\n",
      "Generator Loss at epoch: 0, iter 910 = 5.947484970092773\n",
      "Discriminator Loss at epoch: 0, iter 920 = 0.3632175326347351\n",
      "Generator Loss at epoch: 0, iter 920 = 2.7848997116088867\n",
      "Discriminator Loss at epoch: 0, iter 930 = 0.713329017162323\n",
      "Generator Loss at epoch: 0, iter 930 = 4.391406059265137\n",
      "Discriminator Loss at epoch: 0, iter 940 = 0.7634245753288269\n",
      "Generator Loss at epoch: 0, iter 940 = 4.412217140197754\n",
      "Discriminator Loss at epoch: 0, iter 950 = 1.9200539588928223\n",
      "Generator Loss at epoch: 0, iter 950 = 2.09240460395813\n",
      "Discriminator Loss at epoch: 0, iter 960 = 0.20457640290260315\n",
      "Generator Loss at epoch: 0, iter 960 = 2.986612319946289\n",
      "Discriminator Loss at epoch: 0, iter 970 = 0.4337618350982666\n",
      "Generator Loss at epoch: 0, iter 970 = 2.5391387939453125\n",
      "Discriminator Loss at epoch: 0, iter 980 = 0.3451039791107178\n",
      "Generator Loss at epoch: 0, iter 980 = 2.795058250427246\n",
      "Discriminator Loss at epoch: 0, iter 990 = 0.33828821778297424\n",
      "Generator Loss at epoch: 0, iter 990 = 3.587820053100586\n",
      "Discriminator Loss at epoch: 0, iter 1000 = 0.7483010292053223\n",
      "Generator Loss at epoch: 0, iter 1000 = 4.443408012390137\n",
      "Discriminator Loss at epoch: 0, iter 1010 = 0.7967907190322876\n",
      "Generator Loss at epoch: 0, iter 1010 = 3.3353726863861084\n",
      "Discriminator Loss at epoch: 0, iter 1020 = 1.1008151769638062\n",
      "Generator Loss at epoch: 0, iter 1020 = 2.4140260219573975\n",
      "Discriminator Loss at epoch: 0, iter 1030 = 0.21977975964546204\n",
      "Generator Loss at epoch: 0, iter 1030 = 3.621583938598633\n",
      "Discriminator Loss at epoch: 0, iter 1040 = 0.8621079325675964\n",
      "Generator Loss at epoch: 0, iter 1040 = 0.7689433097839355\n",
      "Discriminator Loss at epoch: 0, iter 1050 = 0.3066941201686859\n",
      "Generator Loss at epoch: 0, iter 1050 = 3.0297398567199707\n",
      "Discriminator Loss at epoch: 0, iter 1060 = 0.5145620703697205\n",
      "Generator Loss at epoch: 0, iter 1060 = 4.259347438812256\n",
      "Discriminator Loss at epoch: 0, iter 1070 = 1.3921223878860474\n",
      "Generator Loss at epoch: 0, iter 1070 = 4.337240219116211\n",
      "Discriminator Loss at epoch: 0, iter 1080 = 0.6924158930778503\n",
      "Generator Loss at epoch: 0, iter 1080 = 3.3633713722229004\n",
      "Discriminator Loss at epoch: 0, iter 1090 = 0.4128829836845398\n",
      "Generator Loss at epoch: 0, iter 1090 = 2.566956043243408\n",
      "Discriminator Loss at epoch: 0, iter 1100 = 0.4476451277732849\n",
      "Generator Loss at epoch: 0, iter 1100 = 3.5607082843780518\n",
      "Discriminator Loss at epoch: 0, iter 1110 = 0.638593316078186\n",
      "Generator Loss at epoch: 0, iter 1110 = 3.4321303367614746\n",
      "Discriminator Loss at epoch: 0, iter 1120 = 0.5106906294822693\n",
      "Generator Loss at epoch: 0, iter 1120 = 4.988374710083008\n",
      "Discriminator Loss at epoch: 0, iter 1130 = 0.3882755637168884\n",
      "Generator Loss at epoch: 0, iter 1130 = 3.196132183074951\n",
      "Discriminator Loss at epoch: 0, iter 1140 = 1.9898186922073364\n",
      "Generator Loss at epoch: 0, iter 1140 = 4.706634521484375\n",
      "Discriminator Loss at epoch: 0, iter 1150 = 3.388474941253662\n",
      "Generator Loss at epoch: 0, iter 1150 = 2.3898632526397705\n",
      "Discriminator Loss at epoch: 0, iter 1160 = 0.5837782621383667\n",
      "Generator Loss at epoch: 0, iter 1160 = 2.901909112930298\n",
      "Discriminator Loss at epoch: 0, iter 1170 = 1.0251617431640625\n",
      "Generator Loss at epoch: 0, iter 1170 = 3.5507071018218994\n",
      "Discriminator Loss at epoch: 0, iter 1180 = 0.988005518913269\n",
      "Generator Loss at epoch: 0, iter 1180 = 3.1992058753967285\n",
      "Discriminator Loss at epoch: 0, iter 1190 = 2.5551137924194336\n",
      "Generator Loss at epoch: 0, iter 1190 = 2.333613872528076\n",
      "Discriminator Loss at epoch: 0, iter 1200 = 0.3235528767108917\n",
      "Generator Loss at epoch: 0, iter 1200 = 3.1410348415374756\n",
      "Discriminator Loss at epoch: 0, iter 1210 = 0.7712618708610535\n",
      "Generator Loss at epoch: 0, iter 1210 = 2.7560081481933594\n",
      "Discriminator Loss at epoch: 0, iter 1220 = 0.3936634063720703\n",
      "Generator Loss at epoch: 0, iter 1220 = 3.3365015983581543\n",
      "Discriminator Loss at epoch: 0, iter 1230 = 0.8051948547363281\n",
      "Generator Loss at epoch: 0, iter 1230 = 2.4783666133880615\n",
      "Discriminator Loss at epoch: 0, iter 1240 = 0.5106556415557861\n",
      "Generator Loss at epoch: 0, iter 1240 = 3.7038588523864746\n",
      "Discriminator Loss at epoch: 0, iter 1250 = 0.7548725605010986\n",
      "Generator Loss at epoch: 0, iter 1250 = 2.409266471862793\n",
      "Discriminator Loss at epoch: 0, iter 1260 = 0.5331225991249084\n",
      "Generator Loss at epoch: 0, iter 1260 = 3.8592450618743896\n",
      "Discriminator Loss at epoch: 0, iter 1270 = 0.5363611578941345\n",
      "Generator Loss at epoch: 0, iter 1270 = 2.518557071685791\n",
      "Discriminator Loss at epoch: 0, iter 1280 = 0.41228288412094116\n",
      "Generator Loss at epoch: 0, iter 1280 = 4.38906717300415\n",
      "Discriminator Loss at epoch: 0, iter 1290 = 0.6566577553749084\n",
      "Generator Loss at epoch: 0, iter 1290 = 3.0163135528564453\n",
      "Discriminator Loss at epoch: 0, iter 1300 = 0.588747501373291\n",
      "Generator Loss at epoch: 0, iter 1300 = 3.148176431655884\n",
      "Discriminator Loss at epoch: 0, iter 1310 = 0.28519973158836365\n",
      "Generator Loss at epoch: 0, iter 1310 = 4.346810340881348\n",
      "Discriminator Loss at epoch: 0, iter 1320 = 0.8068968057632446\n",
      "Generator Loss at epoch: 0, iter 1320 = 3.524019718170166\n",
      "Discriminator Loss at epoch: 0, iter 1330 = 0.4559881091117859\n",
      "Generator Loss at epoch: 0, iter 1330 = 2.867872714996338\n",
      "Discriminator Loss at epoch: 0, iter 1340 = 0.3944687843322754\n",
      "Generator Loss at epoch: 0, iter 1340 = 3.489377021789551\n",
      "Discriminator Loss at epoch: 0, iter 1350 = 1.8943510055541992\n",
      "Generator Loss at epoch: 0, iter 1350 = 4.141083240509033\n",
      "Discriminator Loss at epoch: 0, iter 1360 = 0.6570624709129333\n",
      "Generator Loss at epoch: 0, iter 1360 = 3.2153022289276123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 0, iter 1370 = 0.8715469837188721\n",
      "Generator Loss at epoch: 0, iter 1370 = 3.0148367881774902\n",
      "Discriminator Loss at epoch: 0, iter 1380 = 0.37047117948532104\n",
      "Generator Loss at epoch: 0, iter 1380 = 3.3998124599456787\n",
      "Discriminator Loss at epoch: 0, iter 1390 = 0.22455236315727234\n",
      "Generator Loss at epoch: 0, iter 1390 = 3.5607099533081055\n",
      "Discriminator Loss at epoch: 0, iter 1400 = 0.33175837993621826\n",
      "Generator Loss at epoch: 0, iter 1400 = 3.509444236755371\n",
      "Discriminator Loss at epoch: 0, iter 1410 = 1.0111119747161865\n",
      "Generator Loss at epoch: 0, iter 1410 = 3.230851173400879\n",
      "Discriminator Loss at epoch: 0, iter 1420 = 0.5449591279029846\n",
      "Generator Loss at epoch: 0, iter 1420 = 1.1354732513427734\n",
      "Discriminator Loss at epoch: 0, iter 1430 = 0.3527810871601105\n",
      "Generator Loss at epoch: 0, iter 1430 = 2.692857027053833\n",
      "Discriminator Loss at epoch: 0, iter 1440 = 0.2822660803794861\n",
      "Generator Loss at epoch: 0, iter 1440 = 3.5072648525238037\n",
      "Discriminator Loss at epoch: 0, iter 1450 = 0.8965998888015747\n",
      "Generator Loss at epoch: 0, iter 1450 = 2.722921371459961\n",
      "Discriminator Loss at epoch: 0, iter 1460 = 0.2977299094200134\n",
      "Generator Loss at epoch: 0, iter 1460 = 3.984060049057007\n",
      "Discriminator Loss at epoch: 0, iter 1470 = 0.4537469148635864\n",
      "Generator Loss at epoch: 0, iter 1470 = 3.702643394470215\n",
      "Discriminator Loss at epoch: 0, iter 1480 = 0.5817569494247437\n",
      "Generator Loss at epoch: 0, iter 1480 = 2.6490671634674072\n",
      "Discriminator Loss at epoch: 0, iter 1490 = 0.2582978904247284\n",
      "Generator Loss at epoch: 0, iter 1490 = 4.003220081329346\n",
      "Discriminator Loss at epoch: 0, iter 1500 = 0.23771610856056213\n",
      "Generator Loss at epoch: 0, iter 1500 = 4.002449035644531\n",
      "Discriminator Loss at epoch: 0, iter 1510 = 0.7534193992614746\n",
      "Generator Loss at epoch: 0, iter 1510 = 3.3475894927978516\n",
      "Discriminator Loss at epoch: 0, iter 1520 = 0.45113903284072876\n",
      "Generator Loss at epoch: 0, iter 1520 = 4.239386558532715\n",
      "Discriminator Loss at epoch: 0, iter 1530 = 1.0150525569915771\n",
      "Generator Loss at epoch: 0, iter 1530 = 6.029357433319092\n",
      "Discriminator Loss at epoch: 0, iter 1540 = 0.3916919231414795\n",
      "Generator Loss at epoch: 0, iter 1540 = 3.1442012786865234\n",
      "Discriminator Loss at epoch: 0, iter 1550 = 0.4182770848274231\n",
      "Generator Loss at epoch: 0, iter 1550 = 3.9591031074523926\n",
      "Discriminator Loss at epoch: 0, iter 1560 = 0.5120497345924377\n",
      "Generator Loss at epoch: 0, iter 1560 = 2.763611316680908\n",
      "Discriminator Loss at epoch: 0, iter 1570 = 0.9681668877601624\n",
      "Generator Loss at epoch: 0, iter 1570 = 3.047114372253418\n",
      "Discriminator Loss at epoch: 0, iter 1580 = 0.24073751270771027\n",
      "Generator Loss at epoch: 0, iter 1580 = 3.8647499084472656\n",
      "Discriminator Loss at epoch: 0, iter 1590 = 0.48843076825141907\n",
      "Generator Loss at epoch: 0, iter 1590 = 4.637548923492432\n",
      "Discriminator Loss at epoch: 0, iter 1600 = 0.27759188413619995\n",
      "Generator Loss at epoch: 0, iter 1600 = 3.5123958587646484\n",
      "Discriminator Loss at epoch: 0, iter 1610 = 0.41927313804626465\n",
      "Generator Loss at epoch: 0, iter 1610 = 3.6171650886535645\n",
      "Discriminator Loss at epoch: 0, iter 1620 = 3.3975634574890137\n",
      "Generator Loss at epoch: 0, iter 1620 = 3.897054672241211\n",
      "Discriminator Loss at epoch: 0, iter 1630 = 1.1129918098449707\n",
      "Generator Loss at epoch: 0, iter 1630 = 2.711270332336426\n",
      "Discriminator Loss at epoch: 0, iter 1640 = 0.1799115240573883\n",
      "Generator Loss at epoch: 0, iter 1640 = 3.4341554641723633\n",
      "Discriminator Loss at epoch: 0, iter 1650 = 0.16651588678359985\n",
      "Generator Loss at epoch: 0, iter 1650 = 3.948430061340332\n",
      "Discriminator Loss at epoch: 0, iter 1660 = 2.063232898712158\n",
      "Generator Loss at epoch: 0, iter 1660 = 4.252225875854492\n",
      "Discriminator Loss at epoch: 0, iter 1670 = 1.1067801713943481\n",
      "Generator Loss at epoch: 0, iter 1670 = 4.141661167144775\n",
      "Discriminator Loss at epoch: 0, iter 1680 = 0.5282784700393677\n",
      "Generator Loss at epoch: 0, iter 1680 = 3.1110219955444336\n",
      "Discriminator Loss at epoch: 0, iter 1690 = 0.4058641195297241\n",
      "Generator Loss at epoch: 0, iter 1690 = 3.5929982662200928\n",
      "Discriminator Loss at epoch: 0, iter 1700 = 0.482812762260437\n",
      "Generator Loss at epoch: 0, iter 1700 = 3.1456174850463867\n",
      "Discriminator Loss at epoch: 0, iter 1710 = 0.6814838647842407\n",
      "Generator Loss at epoch: 0, iter 1710 = 3.274250030517578\n",
      "Discriminator Loss at epoch: 0, iter 1720 = 0.5057377815246582\n",
      "Generator Loss at epoch: 0, iter 1720 = 2.181128978729248\n",
      "Discriminator Loss at epoch: 0, iter 1730 = 0.483237624168396\n",
      "Generator Loss at epoch: 0, iter 1730 = 2.9591617584228516\n",
      "Discriminator Loss at epoch: 0, iter 1740 = 0.48550331592559814\n",
      "Generator Loss at epoch: 0, iter 1740 = 3.2298941612243652\n",
      "Discriminator Loss at epoch: 0, iter 1750 = 0.7830657958984375\n",
      "Generator Loss at epoch: 0, iter 1750 = 4.566277503967285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 10%|█         | 1/10 [22:53<3:26:04, 1373.80s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 1, iter 0 = 0.8965212106704712\n",
      "Generator Loss at epoch: 1, iter 0 = 5.349118232727051\n",
      "Discriminator Loss at epoch: 1, iter 10 = 1.199429988861084\n",
      "Generator Loss at epoch: 1, iter 10 = 2.279597282409668\n",
      "Discriminator Loss at epoch: 1, iter 20 = 0.3082229495048523\n",
      "Generator Loss at epoch: 1, iter 20 = 3.275275707244873\n",
      "Discriminator Loss at epoch: 1, iter 30 = 0.7186363339424133\n",
      "Generator Loss at epoch: 1, iter 30 = 2.173389434814453\n",
      "Discriminator Loss at epoch: 1, iter 40 = 0.20340560376644135\n",
      "Generator Loss at epoch: 1, iter 40 = 3.935690402984619\n",
      "Discriminator Loss at epoch: 1, iter 50 = 0.32161617279052734\n",
      "Generator Loss at epoch: 1, iter 50 = 3.8648715019226074\n",
      "Discriminator Loss at epoch: 1, iter 60 = 0.917025625705719\n",
      "Generator Loss at epoch: 1, iter 60 = 4.805911064147949\n",
      "Discriminator Loss at epoch: 1, iter 70 = 0.4586246609687805\n",
      "Generator Loss at epoch: 1, iter 70 = 2.474548578262329\n",
      "Discriminator Loss at epoch: 1, iter 80 = 0.4454667866230011\n",
      "Generator Loss at epoch: 1, iter 80 = 2.8601438999176025\n",
      "Discriminator Loss at epoch: 1, iter 90 = 0.5595508813858032\n",
      "Generator Loss at epoch: 1, iter 90 = 3.202972888946533\n",
      "Discriminator Loss at epoch: 1, iter 100 = 0.4112035036087036\n",
      "Generator Loss at epoch: 1, iter 100 = 4.360044956207275\n",
      "Discriminator Loss at epoch: 1, iter 110 = 1.4738447666168213\n",
      "Generator Loss at epoch: 1, iter 110 = 5.32136869430542\n",
      "Discriminator Loss at epoch: 1, iter 120 = 0.2213534116744995\n",
      "Generator Loss at epoch: 1, iter 120 = 3.287959098815918\n",
      "Discriminator Loss at epoch: 1, iter 130 = 0.18541498482227325\n",
      "Generator Loss at epoch: 1, iter 130 = 4.989020347595215\n",
      "Discriminator Loss at epoch: 1, iter 140 = 0.2876211106777191\n",
      "Generator Loss at epoch: 1, iter 140 = 3.4041340351104736\n",
      "Discriminator Loss at epoch: 1, iter 150 = 0.27416539192199707\n",
      "Generator Loss at epoch: 1, iter 150 = 3.328695774078369\n",
      "Discriminator Loss at epoch: 1, iter 160 = 0.5953514575958252\n",
      "Generator Loss at epoch: 1, iter 160 = 3.6603989601135254\n",
      "Discriminator Loss at epoch: 1, iter 170 = 0.5101359486579895\n",
      "Generator Loss at epoch: 1, iter 170 = 3.125983238220215\n",
      "Discriminator Loss at epoch: 1, iter 180 = 1.109066367149353\n",
      "Generator Loss at epoch: 1, iter 180 = 4.004344463348389\n",
      "Discriminator Loss at epoch: 1, iter 190 = 0.6720107197761536\n",
      "Generator Loss at epoch: 1, iter 190 = 1.9257628917694092\n",
      "Discriminator Loss at epoch: 1, iter 200 = 0.3281250596046448\n",
      "Generator Loss at epoch: 1, iter 200 = 3.819411516189575\n",
      "Discriminator Loss at epoch: 1, iter 210 = 0.3722286820411682\n",
      "Generator Loss at epoch: 1, iter 210 = 3.388436794281006\n",
      "Discriminator Loss at epoch: 1, iter 220 = 1.4262365102767944\n",
      "Generator Loss at epoch: 1, iter 220 = 4.882949352264404\n",
      "Discriminator Loss at epoch: 1, iter 230 = 0.43472811579704285\n",
      "Generator Loss at epoch: 1, iter 230 = 1.8811516761779785\n",
      "Discriminator Loss at epoch: 1, iter 240 = 0.8609606027603149\n",
      "Generator Loss at epoch: 1, iter 240 = 4.024970054626465\n",
      "Discriminator Loss at epoch: 1, iter 250 = 0.22318269312381744\n",
      "Generator Loss at epoch: 1, iter 250 = 3.1716723442077637\n",
      "Discriminator Loss at epoch: 1, iter 260 = 0.5753348469734192\n",
      "Generator Loss at epoch: 1, iter 260 = 4.822270393371582\n",
      "Discriminator Loss at epoch: 1, iter 270 = 0.3981001377105713\n",
      "Generator Loss at epoch: 1, iter 270 = 3.25404691696167\n",
      "Discriminator Loss at epoch: 1, iter 280 = 0.25159329175949097\n",
      "Generator Loss at epoch: 1, iter 280 = 3.42978572845459\n",
      "Discriminator Loss at epoch: 1, iter 290 = 0.38573938608169556\n",
      "Generator Loss at epoch: 1, iter 290 = 4.174703598022461\n",
      "Discriminator Loss at epoch: 1, iter 300 = 0.32488909363746643\n",
      "Generator Loss at epoch: 1, iter 300 = 5.369925498962402\n",
      "Discriminator Loss at epoch: 1, iter 310 = 0.23617497086524963\n",
      "Generator Loss at epoch: 1, iter 310 = 3.652539014816284\n",
      "Discriminator Loss at epoch: 1, iter 320 = 0.3674466609954834\n",
      "Generator Loss at epoch: 1, iter 320 = 3.0379583835601807\n",
      "Discriminator Loss at epoch: 1, iter 330 = 0.3237591087818146\n",
      "Generator Loss at epoch: 1, iter 330 = 3.1317553520202637\n",
      "Discriminator Loss at epoch: 1, iter 340 = 0.11752796918153763\n",
      "Generator Loss at epoch: 1, iter 340 = 3.5565555095672607\n",
      "Discriminator Loss at epoch: 1, iter 350 = 1.3170902729034424\n",
      "Generator Loss at epoch: 1, iter 350 = 4.318169116973877\n",
      "Discriminator Loss at epoch: 1, iter 360 = 0.5362432599067688\n",
      "Generator Loss at epoch: 1, iter 360 = 5.165777206420898\n",
      "Discriminator Loss at epoch: 1, iter 370 = 0.46575239300727844\n",
      "Generator Loss at epoch: 1, iter 370 = 2.8181495666503906\n",
      "Discriminator Loss at epoch: 1, iter 380 = 0.25547555088996887\n",
      "Generator Loss at epoch: 1, iter 380 = 2.4390382766723633\n",
      "Discriminator Loss at epoch: 1, iter 390 = 0.19628071784973145\n",
      "Generator Loss at epoch: 1, iter 390 = 2.976548194885254\n",
      "Discriminator Loss at epoch: 1, iter 400 = 0.15561789274215698\n",
      "Generator Loss at epoch: 1, iter 400 = 3.3276476860046387\n",
      "Discriminator Loss at epoch: 1, iter 410 = 0.34041261672973633\n",
      "Generator Loss at epoch: 1, iter 410 = 5.148270606994629\n",
      "Discriminator Loss at epoch: 1, iter 420 = 0.13351961970329285\n",
      "Generator Loss at epoch: 1, iter 420 = 3.8803367614746094\n",
      "Discriminator Loss at epoch: 1, iter 430 = 0.837102472782135\n",
      "Generator Loss at epoch: 1, iter 430 = 2.284480094909668\n",
      "Discriminator Loss at epoch: 1, iter 440 = 0.5004020929336548\n",
      "Generator Loss at epoch: 1, iter 440 = 4.178816795349121\n",
      "Discriminator Loss at epoch: 1, iter 450 = 0.3065817654132843\n",
      "Generator Loss at epoch: 1, iter 450 = 5.607503414154053\n",
      "Discriminator Loss at epoch: 1, iter 460 = 1.6712195873260498\n",
      "Generator Loss at epoch: 1, iter 460 = 1.9449764490127563\n",
      "Discriminator Loss at epoch: 1, iter 470 = 0.554546594619751\n",
      "Generator Loss at epoch: 1, iter 470 = 2.726961612701416\n",
      "Discriminator Loss at epoch: 1, iter 480 = 0.16602925956249237\n",
      "Generator Loss at epoch: 1, iter 480 = 3.2217843532562256\n",
      "Discriminator Loss at epoch: 1, iter 490 = 0.5859189033508301\n",
      "Generator Loss at epoch: 1, iter 490 = 5.504536151885986\n",
      "Discriminator Loss at epoch: 1, iter 500 = 0.29448264837265015\n",
      "Generator Loss at epoch: 1, iter 500 = 4.001641750335693\n",
      "Discriminator Loss at epoch: 1, iter 510 = 1.0837891101837158\n",
      "Generator Loss at epoch: 1, iter 510 = 3.665020704269409\n",
      "Discriminator Loss at epoch: 1, iter 520 = 0.2907686233520508\n",
      "Generator Loss at epoch: 1, iter 520 = 2.711880683898926\n",
      "Discriminator Loss at epoch: 1, iter 530 = 0.41591984033584595\n",
      "Generator Loss at epoch: 1, iter 530 = 3.6262588500976562\n",
      "Discriminator Loss at epoch: 1, iter 540 = 0.6100956201553345\n",
      "Generator Loss at epoch: 1, iter 540 = 3.262856960296631\n",
      "Discriminator Loss at epoch: 1, iter 550 = 0.7024710774421692\n",
      "Generator Loss at epoch: 1, iter 550 = 2.2208685874938965\n",
      "Discriminator Loss at epoch: 1, iter 560 = 0.7314020395278931\n",
      "Generator Loss at epoch: 1, iter 560 = 2.7893967628479004\n",
      "Discriminator Loss at epoch: 1, iter 570 = 0.5601044297218323\n",
      "Generator Loss at epoch: 1, iter 570 = 3.8575406074523926\n",
      "Discriminator Loss at epoch: 1, iter 580 = 0.45778903365135193\n",
      "Generator Loss at epoch: 1, iter 580 = 2.905851364135742\n",
      "Discriminator Loss at epoch: 1, iter 590 = 0.4073670208454132\n",
      "Generator Loss at epoch: 1, iter 590 = 2.44057035446167\n",
      "Discriminator Loss at epoch: 1, iter 600 = 0.35429647564888\n",
      "Generator Loss at epoch: 1, iter 600 = 2.6874499320983887\n",
      "Discriminator Loss at epoch: 1, iter 610 = 0.6578847169876099\n",
      "Generator Loss at epoch: 1, iter 610 = 3.46518611907959\n",
      "Discriminator Loss at epoch: 1, iter 620 = 0.4443889558315277\n",
      "Generator Loss at epoch: 1, iter 620 = 2.556776523590088\n",
      "Discriminator Loss at epoch: 1, iter 630 = 0.22987470030784607\n",
      "Generator Loss at epoch: 1, iter 630 = 3.045897960662842\n",
      "Discriminator Loss at epoch: 1, iter 640 = 0.30721548199653625\n",
      "Generator Loss at epoch: 1, iter 640 = 5.376399993896484\n",
      "Discriminator Loss at epoch: 1, iter 650 = 0.2881982922554016\n",
      "Generator Loss at epoch: 1, iter 650 = 4.098126411437988\n",
      "Discriminator Loss at epoch: 1, iter 660 = 0.6674935221672058\n",
      "Generator Loss at epoch: 1, iter 660 = 3.821568727493286\n",
      "Discriminator Loss at epoch: 1, iter 670 = 0.5434601306915283\n",
      "Generator Loss at epoch: 1, iter 670 = 2.866933822631836\n",
      "Discriminator Loss at epoch: 1, iter 680 = 0.3158699870109558\n",
      "Generator Loss at epoch: 1, iter 680 = 4.291608810424805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 1, iter 690 = 1.4059122800827026\n",
      "Generator Loss at epoch: 1, iter 690 = 4.286336898803711\n",
      "Discriminator Loss at epoch: 1, iter 700 = 0.5482801198959351\n",
      "Generator Loss at epoch: 1, iter 700 = 2.6676478385925293\n",
      "Discriminator Loss at epoch: 1, iter 710 = 0.2974207103252411\n",
      "Generator Loss at epoch: 1, iter 710 = 3.593747615814209\n",
      "Discriminator Loss at epoch: 1, iter 720 = 0.1745116114616394\n",
      "Generator Loss at epoch: 1, iter 720 = 6.052447319030762\n",
      "Discriminator Loss at epoch: 1, iter 730 = 0.8145339488983154\n",
      "Generator Loss at epoch: 1, iter 730 = 4.8017401695251465\n",
      "Discriminator Loss at epoch: 1, iter 740 = 0.5068588852882385\n",
      "Generator Loss at epoch: 1, iter 740 = 2.858524799346924\n",
      "Discriminator Loss at epoch: 1, iter 750 = 0.459367573261261\n",
      "Generator Loss at epoch: 1, iter 750 = 2.2354934215545654\n",
      "Discriminator Loss at epoch: 1, iter 760 = 0.9212467670440674\n",
      "Generator Loss at epoch: 1, iter 760 = 5.3700480461120605\n",
      "Discriminator Loss at epoch: 1, iter 770 = 1.6395838260650635\n",
      "Generator Loss at epoch: 1, iter 770 = 3.1219983100891113\n",
      "Discriminator Loss at epoch: 1, iter 780 = 0.42396509647369385\n",
      "Generator Loss at epoch: 1, iter 780 = 3.846627950668335\n",
      "Discriminator Loss at epoch: 1, iter 790 = 0.3689037561416626\n",
      "Generator Loss at epoch: 1, iter 790 = 4.892088890075684\n",
      "Discriminator Loss at epoch: 1, iter 800 = 0.6052160859107971\n",
      "Generator Loss at epoch: 1, iter 800 = 4.049551010131836\n",
      "Discriminator Loss at epoch: 1, iter 810 = 0.939728856086731\n",
      "Generator Loss at epoch: 1, iter 810 = 2.6550443172454834\n",
      "Discriminator Loss at epoch: 1, iter 820 = 0.942081093788147\n",
      "Generator Loss at epoch: 1, iter 820 = 2.2055718898773193\n",
      "Discriminator Loss at epoch: 1, iter 830 = 0.8814662098884583\n",
      "Generator Loss at epoch: 1, iter 830 = 5.186456680297852\n",
      "Discriminator Loss at epoch: 1, iter 840 = 0.7472048997879028\n",
      "Generator Loss at epoch: 1, iter 840 = 3.1885299682617188\n",
      "Discriminator Loss at epoch: 1, iter 850 = 0.18611952662467957\n",
      "Generator Loss at epoch: 1, iter 850 = 4.19761323928833\n",
      "Discriminator Loss at epoch: 1, iter 860 = 0.6680733561515808\n",
      "Generator Loss at epoch: 1, iter 860 = 3.7226943969726562\n",
      "Discriminator Loss at epoch: 1, iter 870 = 0.40146395564079285\n",
      "Generator Loss at epoch: 1, iter 870 = 3.1923866271972656\n",
      "Discriminator Loss at epoch: 1, iter 880 = 0.36196309328079224\n",
      "Generator Loss at epoch: 1, iter 880 = 4.8597731590271\n",
      "Discriminator Loss at epoch: 1, iter 890 = 1.1948959827423096\n",
      "Generator Loss at epoch: 1, iter 890 = 10.046072006225586\n",
      "Discriminator Loss at epoch: 1, iter 900 = 0.29950928688049316\n",
      "Generator Loss at epoch: 1, iter 900 = 2.6770246028900146\n",
      "Discriminator Loss at epoch: 1, iter 910 = 0.28281503915786743\n",
      "Generator Loss at epoch: 1, iter 910 = 3.42352294921875\n",
      "Discriminator Loss at epoch: 1, iter 920 = 0.20951879024505615\n",
      "Generator Loss at epoch: 1, iter 920 = 3.5914759635925293\n",
      "Discriminator Loss at epoch: 1, iter 930 = 0.09169697016477585\n",
      "Generator Loss at epoch: 1, iter 930 = 3.5216803550720215\n",
      "Discriminator Loss at epoch: 1, iter 940 = 0.5511032342910767\n",
      "Generator Loss at epoch: 1, iter 940 = 3.8796801567077637\n",
      "Discriminator Loss at epoch: 1, iter 950 = 0.6104516983032227\n",
      "Generator Loss at epoch: 1, iter 950 = 3.4004430770874023\n",
      "Discriminator Loss at epoch: 1, iter 960 = 0.6303704380989075\n",
      "Generator Loss at epoch: 1, iter 960 = 9.188946723937988\n",
      "Discriminator Loss at epoch: 1, iter 970 = 0.5975417494773865\n",
      "Generator Loss at epoch: 1, iter 970 = 2.976290702819824\n",
      "Discriminator Loss at epoch: 1, iter 980 = 0.5206152200698853\n",
      "Generator Loss at epoch: 1, iter 980 = 3.7915303707122803\n",
      "Discriminator Loss at epoch: 1, iter 990 = 0.7105793356895447\n",
      "Generator Loss at epoch: 1, iter 990 = 3.4748148918151855\n",
      "Discriminator Loss at epoch: 1, iter 1000 = 0.5099263787269592\n",
      "Generator Loss at epoch: 1, iter 1000 = 3.292144775390625\n",
      "Discriminator Loss at epoch: 1, iter 1010 = 0.4221862554550171\n",
      "Generator Loss at epoch: 1, iter 1010 = 5.44366455078125\n",
      "Discriminator Loss at epoch: 1, iter 1020 = 0.12192197144031525\n",
      "Generator Loss at epoch: 1, iter 1020 = 4.2209672927856445\n",
      "Discriminator Loss at epoch: 1, iter 1030 = 0.16117388010025024\n",
      "Generator Loss at epoch: 1, iter 1030 = 2.9082181453704834\n",
      "Discriminator Loss at epoch: 1, iter 1040 = 0.3435496687889099\n",
      "Generator Loss at epoch: 1, iter 1040 = 2.917431354522705\n",
      "Discriminator Loss at epoch: 1, iter 1050 = 0.6456478834152222\n",
      "Generator Loss at epoch: 1, iter 1050 = 3.604724884033203\n",
      "Discriminator Loss at epoch: 1, iter 1060 = 0.2964932918548584\n",
      "Generator Loss at epoch: 1, iter 1060 = 3.296605110168457\n",
      "Discriminator Loss at epoch: 1, iter 1070 = 0.5479791164398193\n",
      "Generator Loss at epoch: 1, iter 1070 = 5.470210552215576\n",
      "Discriminator Loss at epoch: 1, iter 1080 = 0.3122360408306122\n",
      "Generator Loss at epoch: 1, iter 1080 = 4.096097946166992\n",
      "Discriminator Loss at epoch: 1, iter 1090 = 0.09026531875133514\n",
      "Generator Loss at epoch: 1, iter 1090 = 4.258661270141602\n",
      "Discriminator Loss at epoch: 1, iter 1100 = 0.5521447658538818\n",
      "Generator Loss at epoch: 1, iter 1100 = 4.0586042404174805\n",
      "Discriminator Loss at epoch: 1, iter 1110 = 1.4745842218399048\n",
      "Generator Loss at epoch: 1, iter 1110 = 3.1702189445495605\n",
      "Discriminator Loss at epoch: 1, iter 1120 = 1.3794020414352417\n",
      "Generator Loss at epoch: 1, iter 1120 = 8.588132858276367\n",
      "Discriminator Loss at epoch: 1, iter 1130 = 0.3463684916496277\n",
      "Generator Loss at epoch: 1, iter 1130 = 3.2959494590759277\n",
      "Discriminator Loss at epoch: 1, iter 1140 = 0.20330029726028442\n",
      "Generator Loss at epoch: 1, iter 1140 = 3.511831760406494\n",
      "Discriminator Loss at epoch: 1, iter 1150 = 0.11842349171638489\n",
      "Generator Loss at epoch: 1, iter 1150 = 4.1615400314331055\n",
      "Discriminator Loss at epoch: 1, iter 1160 = 0.18289747834205627\n",
      "Generator Loss at epoch: 1, iter 1160 = 3.818631172180176\n",
      "Discriminator Loss at epoch: 1, iter 1170 = 0.21099549531936646\n",
      "Generator Loss at epoch: 1, iter 1170 = 4.1465277671813965\n",
      "Discriminator Loss at epoch: 1, iter 1180 = 0.18818117678165436\n",
      "Generator Loss at epoch: 1, iter 1180 = 3.1755189895629883\n",
      "Discriminator Loss at epoch: 1, iter 1190 = 0.5727208852767944\n",
      "Generator Loss at epoch: 1, iter 1190 = 2.0992588996887207\n",
      "Discriminator Loss at epoch: 1, iter 1200 = 0.22759301960468292\n",
      "Generator Loss at epoch: 1, iter 1200 = 3.5678038597106934\n",
      "Discriminator Loss at epoch: 1, iter 1210 = 0.10629452019929886\n",
      "Generator Loss at epoch: 1, iter 1210 = 5.3198089599609375\n",
      "Discriminator Loss at epoch: 1, iter 1220 = 0.46230965852737427\n",
      "Generator Loss at epoch: 1, iter 1220 = 5.330272197723389\n",
      "Discriminator Loss at epoch: 1, iter 1230 = 0.7726008892059326\n",
      "Generator Loss at epoch: 1, iter 1230 = 3.968222141265869\n",
      "Discriminator Loss at epoch: 1, iter 1240 = 0.21595899760723114\n",
      "Generator Loss at epoch: 1, iter 1240 = 4.632261276245117\n",
      "Discriminator Loss at epoch: 1, iter 1250 = 1.3950483798980713\n",
      "Generator Loss at epoch: 1, iter 1250 = 5.199445724487305\n",
      "Discriminator Loss at epoch: 1, iter 1260 = 0.7577519416809082\n",
      "Generator Loss at epoch: 1, iter 1260 = 3.9775609970092773\n",
      "Discriminator Loss at epoch: 1, iter 1270 = 1.0862162113189697\n",
      "Generator Loss at epoch: 1, iter 1270 = 3.0358829498291016\n",
      "Discriminator Loss at epoch: 1, iter 1280 = 0.3747468590736389\n",
      "Generator Loss at epoch: 1, iter 1280 = 2.9757578372955322\n",
      "Discriminator Loss at epoch: 1, iter 1290 = 0.945799708366394\n",
      "Generator Loss at epoch: 1, iter 1290 = 3.8468971252441406\n",
      "Discriminator Loss at epoch: 1, iter 1300 = 0.6988369226455688\n",
      "Generator Loss at epoch: 1, iter 1300 = 2.2621827125549316\n",
      "Discriminator Loss at epoch: 1, iter 1310 = 0.3181995749473572\n",
      "Generator Loss at epoch: 1, iter 1310 = 2.697901487350464\n",
      "Discriminator Loss at epoch: 1, iter 1320 = 0.18472611904144287\n",
      "Generator Loss at epoch: 1, iter 1320 = 3.4506289958953857\n",
      "Discriminator Loss at epoch: 1, iter 1330 = 1.2795544862747192\n",
      "Generator Loss at epoch: 1, iter 1330 = 7.273930549621582\n",
      "Discriminator Loss at epoch: 1, iter 1340 = 0.25775906443595886\n",
      "Generator Loss at epoch: 1, iter 1340 = 2.690326690673828\n",
      "Discriminator Loss at epoch: 1, iter 1350 = 0.3083382844924927\n",
      "Generator Loss at epoch: 1, iter 1350 = 3.563333034515381\n",
      "Discriminator Loss at epoch: 1, iter 1360 = 1.0078164339065552\n",
      "Generator Loss at epoch: 1, iter 1360 = 8.933050155639648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 1, iter 1370 = 0.7140134572982788\n",
      "Generator Loss at epoch: 1, iter 1370 = 4.425264358520508\n",
      "Discriminator Loss at epoch: 1, iter 1380 = 0.5594560503959656\n",
      "Generator Loss at epoch: 1, iter 1380 = 3.855586528778076\n",
      "Discriminator Loss at epoch: 1, iter 1390 = 0.4998571574687958\n",
      "Generator Loss at epoch: 1, iter 1390 = 4.996293067932129\n",
      "Discriminator Loss at epoch: 1, iter 1400 = 0.20221570134162903\n",
      "Generator Loss at epoch: 1, iter 1400 = 4.505044460296631\n",
      "Discriminator Loss at epoch: 1, iter 1410 = 0.5137996673583984\n",
      "Generator Loss at epoch: 1, iter 1410 = 5.125196933746338\n",
      "Discriminator Loss at epoch: 1, iter 1420 = 0.9355617761611938\n",
      "Generator Loss at epoch: 1, iter 1420 = 2.669576406478882\n",
      "Discriminator Loss at epoch: 1, iter 1430 = 0.36271870136260986\n",
      "Generator Loss at epoch: 1, iter 1430 = 3.775750160217285\n",
      "Discriminator Loss at epoch: 1, iter 1440 = 0.17896848917007446\n",
      "Generator Loss at epoch: 1, iter 1440 = 4.46954870223999\n",
      "Discriminator Loss at epoch: 1, iter 1450 = 0.5379248261451721\n",
      "Generator Loss at epoch: 1, iter 1450 = 4.260781288146973\n",
      "Discriminator Loss at epoch: 1, iter 1460 = 0.17918699979782104\n",
      "Generator Loss at epoch: 1, iter 1460 = 5.407177925109863\n",
      "Discriminator Loss at epoch: 1, iter 1470 = 1.1258231401443481\n",
      "Generator Loss at epoch: 1, iter 1470 = 3.4627938270568848\n",
      "Discriminator Loss at epoch: 1, iter 1480 = 0.7742570638656616\n",
      "Generator Loss at epoch: 1, iter 1480 = 3.6000900268554688\n",
      "Discriminator Loss at epoch: 1, iter 1490 = 0.36737799644470215\n",
      "Generator Loss at epoch: 1, iter 1490 = 4.518486976623535\n",
      "Discriminator Loss at epoch: 1, iter 1500 = 0.5099383592605591\n",
      "Generator Loss at epoch: 1, iter 1500 = 3.5971765518188477\n",
      "Discriminator Loss at epoch: 1, iter 1510 = 0.40295806527137756\n",
      "Generator Loss at epoch: 1, iter 1510 = 4.724242210388184\n",
      "Discriminator Loss at epoch: 1, iter 1520 = 0.6578313112258911\n",
      "Generator Loss at epoch: 1, iter 1520 = 5.2581024169921875\n",
      "Discriminator Loss at epoch: 1, iter 1530 = 0.5760897397994995\n",
      "Generator Loss at epoch: 1, iter 1530 = 3.0106186866760254\n",
      "Discriminator Loss at epoch: 1, iter 1540 = 0.3180544972419739\n",
      "Generator Loss at epoch: 1, iter 1540 = 4.554821968078613\n",
      "Discriminator Loss at epoch: 1, iter 1550 = 0.9439579248428345\n",
      "Generator Loss at epoch: 1, iter 1550 = 8.301389694213867\n",
      "Discriminator Loss at epoch: 1, iter 1560 = 0.5188408493995667\n",
      "Generator Loss at epoch: 1, iter 1560 = 3.1887173652648926\n",
      "Discriminator Loss at epoch: 1, iter 1570 = 0.7941179275512695\n",
      "Generator Loss at epoch: 1, iter 1570 = 2.564484119415283\n",
      "Discriminator Loss at epoch: 1, iter 1580 = 0.20309506356716156\n",
      "Generator Loss at epoch: 1, iter 1580 = 3.3012075424194336\n",
      "Discriminator Loss at epoch: 1, iter 1590 = 0.5198781490325928\n",
      "Generator Loss at epoch: 1, iter 1590 = 5.287482738494873\n",
      "Discriminator Loss at epoch: 1, iter 1600 = 0.1471976637840271\n",
      "Generator Loss at epoch: 1, iter 1600 = 4.421297073364258\n",
      "Discriminator Loss at epoch: 1, iter 1610 = 0.4549429714679718\n",
      "Generator Loss at epoch: 1, iter 1610 = 3.8338165283203125\n",
      "Discriminator Loss at epoch: 1, iter 1620 = 0.5096244215965271\n",
      "Generator Loss at epoch: 1, iter 1620 = 4.641840934753418\n",
      "Discriminator Loss at epoch: 1, iter 1630 = 0.3259560763835907\n",
      "Generator Loss at epoch: 1, iter 1630 = 3.473177194595337\n",
      "Discriminator Loss at epoch: 1, iter 1640 = 0.32005032896995544\n",
      "Generator Loss at epoch: 1, iter 1640 = 3.6907541751861572\n",
      "Discriminator Loss at epoch: 1, iter 1650 = 0.531757116317749\n",
      "Generator Loss at epoch: 1, iter 1650 = 3.262784481048584\n",
      "Discriminator Loss at epoch: 1, iter 1660 = 0.3916711211204529\n",
      "Generator Loss at epoch: 1, iter 1660 = 2.49771785736084\n",
      "Discriminator Loss at epoch: 1, iter 1670 = 0.33908766508102417\n",
      "Generator Loss at epoch: 1, iter 1670 = 4.1053667068481445\n",
      "Discriminator Loss at epoch: 1, iter 1680 = 0.3211228847503662\n",
      "Generator Loss at epoch: 1, iter 1680 = 5.846090793609619\n",
      "Discriminator Loss at epoch: 1, iter 1690 = 1.2686967849731445\n",
      "Generator Loss at epoch: 1, iter 1690 = 5.787569522857666\n",
      "Discriminator Loss at epoch: 1, iter 1700 = 1.0121490955352783\n",
      "Generator Loss at epoch: 1, iter 1700 = 2.059084892272949\n",
      "Discriminator Loss at epoch: 1, iter 1710 = 0.31607306003570557\n",
      "Generator Loss at epoch: 1, iter 1710 = 3.6642446517944336\n",
      "Discriminator Loss at epoch: 1, iter 1720 = 0.2246716320514679\n",
      "Generator Loss at epoch: 1, iter 1720 = 4.7754621505737305\n",
      "Discriminator Loss at epoch: 1, iter 1730 = 0.44812333583831787\n",
      "Generator Loss at epoch: 1, iter 1730 = 4.740507125854492\n",
      "Discriminator Loss at epoch: 1, iter 1740 = 0.7271933555603027\n",
      "Generator Loss at epoch: 1, iter 1740 = 6.324239730834961\n",
      "Discriminator Loss at epoch: 1, iter 1750 = 0.3634929656982422\n",
      "Generator Loss at epoch: 1, iter 1750 = 3.926719903945923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 20%|██        | 2/10 [45:40<3:02:52, 1371.59s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 2, iter 0 = 0.3700067102909088\n",
      "Generator Loss at epoch: 2, iter 0 = 2.703176498413086\n",
      "Discriminator Loss at epoch: 2, iter 10 = 0.540235161781311\n",
      "Generator Loss at epoch: 2, iter 10 = 6.951602458953857\n",
      "Discriminator Loss at epoch: 2, iter 20 = 0.16911283135414124\n",
      "Generator Loss at epoch: 2, iter 20 = 3.6385302543640137\n",
      "Discriminator Loss at epoch: 2, iter 30 = 0.2845982611179352\n",
      "Generator Loss at epoch: 2, iter 30 = 2.8155674934387207\n",
      "Discriminator Loss at epoch: 2, iter 40 = 0.5450528264045715\n",
      "Generator Loss at epoch: 2, iter 40 = 4.035794258117676\n",
      "Discriminator Loss at epoch: 2, iter 50 = 0.6965581774711609\n",
      "Generator Loss at epoch: 2, iter 50 = 5.365011215209961\n",
      "Discriminator Loss at epoch: 2, iter 60 = 0.8429873585700989\n",
      "Generator Loss at epoch: 2, iter 60 = 3.5985727310180664\n",
      "Discriminator Loss at epoch: 2, iter 70 = 0.2674090266227722\n",
      "Generator Loss at epoch: 2, iter 70 = 2.838999032974243\n",
      "Discriminator Loss at epoch: 2, iter 80 = 1.216196894645691\n",
      "Generator Loss at epoch: 2, iter 80 = 6.460396766662598\n",
      "Discriminator Loss at epoch: 2, iter 90 = 0.4372245669364929\n",
      "Generator Loss at epoch: 2, iter 90 = 3.340808868408203\n",
      "Discriminator Loss at epoch: 2, iter 100 = 0.4209527373313904\n",
      "Generator Loss at epoch: 2, iter 100 = 3.416900157928467\n",
      "Discriminator Loss at epoch: 2, iter 110 = 0.9438965916633606\n",
      "Generator Loss at epoch: 2, iter 110 = 5.9765400886535645\n",
      "Discriminator Loss at epoch: 2, iter 120 = 0.4658190608024597\n",
      "Generator Loss at epoch: 2, iter 120 = 3.5573713779449463\n",
      "Discriminator Loss at epoch: 2, iter 130 = 0.4314933717250824\n",
      "Generator Loss at epoch: 2, iter 130 = 3.1179709434509277\n",
      "Discriminator Loss at epoch: 2, iter 140 = 0.41494035720825195\n",
      "Generator Loss at epoch: 2, iter 140 = 3.6174492835998535\n",
      "Discriminator Loss at epoch: 2, iter 150 = 0.3381116986274719\n",
      "Generator Loss at epoch: 2, iter 150 = 3.510207176208496\n",
      "Discriminator Loss at epoch: 2, iter 160 = 0.5701791644096375\n",
      "Generator Loss at epoch: 2, iter 160 = 3.8772811889648438\n",
      "Discriminator Loss at epoch: 2, iter 170 = 0.37617188692092896\n",
      "Generator Loss at epoch: 2, iter 170 = 3.5793819427490234\n",
      "Discriminator Loss at epoch: 2, iter 180 = 0.16652463376522064\n",
      "Generator Loss at epoch: 2, iter 180 = 3.207423210144043\n",
      "Discriminator Loss at epoch: 2, iter 190 = 0.23037779331207275\n",
      "Generator Loss at epoch: 2, iter 190 = 3.783708095550537\n",
      "Discriminator Loss at epoch: 2, iter 200 = 0.5088592767715454\n",
      "Generator Loss at epoch: 2, iter 200 = 3.396373748779297\n",
      "Discriminator Loss at epoch: 2, iter 210 = 0.14038681983947754\n",
      "Generator Loss at epoch: 2, iter 210 = 6.811596870422363\n",
      "Discriminator Loss at epoch: 2, iter 220 = 1.477003574371338\n",
      "Generator Loss at epoch: 2, iter 220 = 3.9467315673828125\n",
      "Discriminator Loss at epoch: 2, iter 230 = 1.2182315587997437\n",
      "Generator Loss at epoch: 2, iter 230 = 5.247081756591797\n",
      "Discriminator Loss at epoch: 2, iter 240 = 0.24480919539928436\n",
      "Generator Loss at epoch: 2, iter 240 = 3.420478343963623\n",
      "Discriminator Loss at epoch: 2, iter 250 = 0.3921229839324951\n",
      "Generator Loss at epoch: 2, iter 250 = 2.7617745399475098\n",
      "Discriminator Loss at epoch: 2, iter 260 = 0.2645568251609802\n",
      "Generator Loss at epoch: 2, iter 260 = 3.1874642372131348\n",
      "Discriminator Loss at epoch: 2, iter 270 = 0.3832732141017914\n",
      "Generator Loss at epoch: 2, iter 270 = 4.109997272491455\n",
      "Discriminator Loss at epoch: 2, iter 280 = 0.4442189037799835\n",
      "Generator Loss at epoch: 2, iter 280 = 4.1566081047058105\n",
      "Discriminator Loss at epoch: 2, iter 290 = 0.44690656661987305\n",
      "Generator Loss at epoch: 2, iter 290 = 2.356764793395996\n",
      "Discriminator Loss at epoch: 2, iter 300 = 0.694774866104126\n",
      "Generator Loss at epoch: 2, iter 300 = 3.092535972595215\n",
      "Discriminator Loss at epoch: 2, iter 310 = 0.27799585461616516\n",
      "Generator Loss at epoch: 2, iter 310 = 3.097693920135498\n",
      "Discriminator Loss at epoch: 2, iter 320 = 0.5128273963928223\n",
      "Generator Loss at epoch: 2, iter 320 = 5.689118385314941\n",
      "Discriminator Loss at epoch: 2, iter 330 = 0.1958431601524353\n",
      "Generator Loss at epoch: 2, iter 330 = 4.5212860107421875\n",
      "Discriminator Loss at epoch: 2, iter 340 = 0.2014250010251999\n",
      "Generator Loss at epoch: 2, iter 340 = 5.678463459014893\n",
      "Discriminator Loss at epoch: 2, iter 350 = 0.4732761085033417\n",
      "Generator Loss at epoch: 2, iter 350 = 5.161654949188232\n",
      "Discriminator Loss at epoch: 2, iter 360 = 0.364715039730072\n",
      "Generator Loss at epoch: 2, iter 360 = 4.540279388427734\n",
      "Discriminator Loss at epoch: 2, iter 370 = 0.3589918613433838\n",
      "Generator Loss at epoch: 2, iter 370 = 4.970029354095459\n",
      "Discriminator Loss at epoch: 2, iter 380 = 0.317383348941803\n",
      "Generator Loss at epoch: 2, iter 380 = 3.768718719482422\n",
      "Discriminator Loss at epoch: 2, iter 390 = 0.34109997749328613\n",
      "Generator Loss at epoch: 2, iter 390 = 3.4877214431762695\n",
      "Discriminator Loss at epoch: 2, iter 400 = 0.45844438672065735\n",
      "Generator Loss at epoch: 2, iter 400 = 4.422680377960205\n",
      "Discriminator Loss at epoch: 2, iter 410 = 0.27168038487434387\n",
      "Generator Loss at epoch: 2, iter 410 = 5.017298698425293\n",
      "Discriminator Loss at epoch: 2, iter 420 = 0.20439019799232483\n",
      "Generator Loss at epoch: 2, iter 420 = 4.179937362670898\n",
      "Discriminator Loss at epoch: 2, iter 430 = 0.3661971092224121\n",
      "Generator Loss at epoch: 2, iter 430 = 3.4171230792999268\n",
      "Discriminator Loss at epoch: 2, iter 440 = 0.3384174108505249\n",
      "Generator Loss at epoch: 2, iter 440 = 3.2680187225341797\n",
      "Discriminator Loss at epoch: 2, iter 450 = 0.6760281920433044\n",
      "Generator Loss at epoch: 2, iter 450 = 4.832465648651123\n",
      "Discriminator Loss at epoch: 2, iter 460 = 1.049321174621582\n",
      "Generator Loss at epoch: 2, iter 460 = 4.657076358795166\n",
      "Discriminator Loss at epoch: 2, iter 470 = 1.055132508277893\n",
      "Generator Loss at epoch: 2, iter 470 = 2.2265617847442627\n",
      "Discriminator Loss at epoch: 2, iter 480 = 0.48267242312431335\n",
      "Generator Loss at epoch: 2, iter 480 = 3.681483268737793\n",
      "Discriminator Loss at epoch: 2, iter 490 = 0.09519948065280914\n",
      "Generator Loss at epoch: 2, iter 490 = 4.153038024902344\n",
      "Discriminator Loss at epoch: 2, iter 500 = 0.4986727833747864\n",
      "Generator Loss at epoch: 2, iter 500 = 6.657544136047363\n",
      "Discriminator Loss at epoch: 2, iter 510 = 0.4808967709541321\n",
      "Generator Loss at epoch: 2, iter 510 = 2.595614194869995\n",
      "Discriminator Loss at epoch: 2, iter 520 = 0.1906951665878296\n",
      "Generator Loss at epoch: 2, iter 520 = 3.526355266571045\n",
      "Discriminator Loss at epoch: 2, iter 530 = 0.2790547013282776\n",
      "Generator Loss at epoch: 2, iter 530 = 2.6435399055480957\n",
      "Discriminator Loss at epoch: 2, iter 540 = 0.29866087436676025\n",
      "Generator Loss at epoch: 2, iter 540 = 2.6464006900787354\n",
      "Discriminator Loss at epoch: 2, iter 550 = 0.5685349702835083\n",
      "Generator Loss at epoch: 2, iter 550 = 5.0340046882629395\n",
      "Discriminator Loss at epoch: 2, iter 560 = 0.21036523580551147\n",
      "Generator Loss at epoch: 2, iter 560 = 4.133285045623779\n",
      "Discriminator Loss at epoch: 2, iter 570 = 0.3966572880744934\n",
      "Generator Loss at epoch: 2, iter 570 = 5.148451328277588\n",
      "Discriminator Loss at epoch: 2, iter 580 = 0.30567657947540283\n",
      "Generator Loss at epoch: 2, iter 580 = 4.33340311050415\n",
      "Discriminator Loss at epoch: 2, iter 590 = 0.5339962840080261\n",
      "Generator Loss at epoch: 2, iter 590 = 3.448821783065796\n",
      "Discriminator Loss at epoch: 2, iter 600 = 0.25469765067100525\n",
      "Generator Loss at epoch: 2, iter 600 = 2.639713764190674\n",
      "Discriminator Loss at epoch: 2, iter 610 = 0.17244771122932434\n",
      "Generator Loss at epoch: 2, iter 610 = 2.801492691040039\n",
      "Discriminator Loss at epoch: 2, iter 620 = 0.1643490493297577\n",
      "Generator Loss at epoch: 2, iter 620 = 3.4890642166137695\n",
      "Discriminator Loss at epoch: 2, iter 630 = 0.2660505771636963\n",
      "Generator Loss at epoch: 2, iter 630 = 3.523463249206543\n",
      "Discriminator Loss at epoch: 2, iter 640 = 0.10993202030658722\n",
      "Generator Loss at epoch: 2, iter 640 = 4.050718784332275\n",
      "Discriminator Loss at epoch: 2, iter 650 = 0.0482298843562603\n",
      "Generator Loss at epoch: 2, iter 650 = 5.990056037902832\n",
      "Discriminator Loss at epoch: 2, iter 660 = 0.6118714809417725\n",
      "Generator Loss at epoch: 2, iter 660 = 2.8967745304107666\n",
      "Discriminator Loss at epoch: 2, iter 670 = 0.23550564050674438\n",
      "Generator Loss at epoch: 2, iter 670 = 2.843060255050659\n",
      "Discriminator Loss at epoch: 2, iter 680 = 0.5564916729927063\n",
      "Generator Loss at epoch: 2, iter 680 = 2.9231104850769043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 2, iter 690 = 0.47911548614501953\n",
      "Generator Loss at epoch: 2, iter 690 = 3.800398111343384\n",
      "Discriminator Loss at epoch: 2, iter 700 = 0.22018323838710785\n",
      "Generator Loss at epoch: 2, iter 700 = 3.4985339641571045\n",
      "Discriminator Loss at epoch: 2, iter 710 = 0.4556635320186615\n",
      "Generator Loss at epoch: 2, iter 710 = 3.3327388763427734\n",
      "Discriminator Loss at epoch: 2, iter 720 = 0.4420013427734375\n",
      "Generator Loss at epoch: 2, iter 720 = 2.956904411315918\n",
      "Discriminator Loss at epoch: 2, iter 730 = 0.7037281394004822\n",
      "Generator Loss at epoch: 2, iter 730 = 1.9089399576187134\n",
      "Discriminator Loss at epoch: 2, iter 740 = 0.5158288478851318\n",
      "Generator Loss at epoch: 2, iter 740 = 1.8643758296966553\n",
      "Discriminator Loss at epoch: 2, iter 750 = 0.309274286031723\n",
      "Generator Loss at epoch: 2, iter 750 = 3.9008936882019043\n",
      "Discriminator Loss at epoch: 2, iter 760 = 0.5567043423652649\n",
      "Generator Loss at epoch: 2, iter 760 = 3.979093313217163\n",
      "Discriminator Loss at epoch: 2, iter 770 = 0.38597017526626587\n",
      "Generator Loss at epoch: 2, iter 770 = 3.9679455757141113\n",
      "Discriminator Loss at epoch: 2, iter 780 = 0.6161302328109741\n",
      "Generator Loss at epoch: 2, iter 780 = 2.697782039642334\n",
      "Discriminator Loss at epoch: 2, iter 790 = 0.45329347252845764\n",
      "Generator Loss at epoch: 2, iter 790 = 3.9254250526428223\n",
      "Discriminator Loss at epoch: 2, iter 800 = 0.6623674035072327\n",
      "Generator Loss at epoch: 2, iter 800 = 4.312665939331055\n",
      "Discriminator Loss at epoch: 2, iter 810 = 0.2015458196401596\n",
      "Generator Loss at epoch: 2, iter 810 = 3.9791738986968994\n",
      "Discriminator Loss at epoch: 2, iter 820 = 0.2802393138408661\n",
      "Generator Loss at epoch: 2, iter 820 = 4.738351821899414\n",
      "Discriminator Loss at epoch: 2, iter 830 = 0.20626965165138245\n",
      "Generator Loss at epoch: 2, iter 830 = 3.7578020095825195\n",
      "Discriminator Loss at epoch: 2, iter 840 = 0.35256773233413696\n",
      "Generator Loss at epoch: 2, iter 840 = 4.801198482513428\n",
      "Discriminator Loss at epoch: 2, iter 850 = 0.5349060297012329\n",
      "Generator Loss at epoch: 2, iter 850 = 3.8727571964263916\n",
      "Discriminator Loss at epoch: 2, iter 860 = 0.5785338282585144\n",
      "Generator Loss at epoch: 2, iter 860 = 3.7349820137023926\n",
      "Discriminator Loss at epoch: 2, iter 870 = 0.41865605115890503\n",
      "Generator Loss at epoch: 2, iter 870 = 2.782146453857422\n",
      "Discriminator Loss at epoch: 2, iter 880 = 0.2349737584590912\n",
      "Generator Loss at epoch: 2, iter 880 = 3.0392651557922363\n",
      "Discriminator Loss at epoch: 2, iter 890 = 0.3195542097091675\n",
      "Generator Loss at epoch: 2, iter 890 = 1.9355353116989136\n",
      "Discriminator Loss at epoch: 2, iter 900 = 0.2468409538269043\n",
      "Generator Loss at epoch: 2, iter 900 = 3.8273208141326904\n",
      "Discriminator Loss at epoch: 2, iter 910 = 0.539086639881134\n",
      "Generator Loss at epoch: 2, iter 910 = 2.7103991508483887\n",
      "Discriminator Loss at epoch: 2, iter 920 = 0.34739139676094055\n",
      "Generator Loss at epoch: 2, iter 920 = 4.3298797607421875\n",
      "Discriminator Loss at epoch: 2, iter 930 = 0.2777894139289856\n",
      "Generator Loss at epoch: 2, iter 930 = 4.162171363830566\n",
      "Discriminator Loss at epoch: 2, iter 940 = 0.43185269832611084\n",
      "Generator Loss at epoch: 2, iter 940 = 3.9363365173339844\n",
      "Discriminator Loss at epoch: 2, iter 950 = 1.0557670593261719\n",
      "Generator Loss at epoch: 2, iter 950 = 2.144510269165039\n",
      "Discriminator Loss at epoch: 2, iter 960 = 0.6302669644355774\n",
      "Generator Loss at epoch: 2, iter 960 = 3.4150702953338623\n",
      "Discriminator Loss at epoch: 2, iter 970 = 0.3381914794445038\n",
      "Generator Loss at epoch: 2, iter 970 = 2.9546291828155518\n",
      "Discriminator Loss at epoch: 2, iter 980 = 0.5183607339859009\n",
      "Generator Loss at epoch: 2, iter 980 = 3.9281160831451416\n",
      "Discriminator Loss at epoch: 2, iter 990 = 0.21969109773635864\n",
      "Generator Loss at epoch: 2, iter 990 = 3.182119369506836\n",
      "Discriminator Loss at epoch: 2, iter 1000 = 0.8395503759384155\n",
      "Generator Loss at epoch: 2, iter 1000 = 5.769490718841553\n",
      "Discriminator Loss at epoch: 2, iter 1010 = 0.29577764868736267\n",
      "Generator Loss at epoch: 2, iter 1010 = 3.8714542388916016\n",
      "Discriminator Loss at epoch: 2, iter 1020 = 0.7600581049919128\n",
      "Generator Loss at epoch: 2, iter 1020 = 6.917654991149902\n",
      "Discriminator Loss at epoch: 2, iter 1030 = 0.3966946601867676\n",
      "Generator Loss at epoch: 2, iter 1030 = 4.3995256423950195\n",
      "Discriminator Loss at epoch: 2, iter 1040 = 0.426118403673172\n",
      "Generator Loss at epoch: 2, iter 1040 = 2.970782995223999\n",
      "Discriminator Loss at epoch: 2, iter 1050 = 0.6254430413246155\n",
      "Generator Loss at epoch: 2, iter 1050 = 3.43843936920166\n",
      "Discriminator Loss at epoch: 2, iter 1060 = 0.14771078526973724\n",
      "Generator Loss at epoch: 2, iter 1060 = 4.741864204406738\n",
      "Discriminator Loss at epoch: 2, iter 1070 = 0.6723239421844482\n",
      "Generator Loss at epoch: 2, iter 1070 = 3.9904234409332275\n",
      "Discriminator Loss at epoch: 2, iter 1080 = 0.2632491886615753\n",
      "Generator Loss at epoch: 2, iter 1080 = 6.145819664001465\n",
      "Discriminator Loss at epoch: 2, iter 1090 = 0.43777263164520264\n",
      "Generator Loss at epoch: 2, iter 1090 = 3.77878999710083\n",
      "Discriminator Loss at epoch: 2, iter 1100 = 0.6282433271408081\n",
      "Generator Loss at epoch: 2, iter 1100 = 3.223668098449707\n",
      "Discriminator Loss at epoch: 2, iter 1110 = 0.8052604794502258\n",
      "Generator Loss at epoch: 2, iter 1110 = 3.173353433609009\n",
      "Discriminator Loss at epoch: 2, iter 1120 = 0.26511508226394653\n",
      "Generator Loss at epoch: 2, iter 1120 = 5.141571998596191\n",
      "Discriminator Loss at epoch: 2, iter 1130 = 0.6415249705314636\n",
      "Generator Loss at epoch: 2, iter 1130 = 3.0274181365966797\n",
      "Discriminator Loss at epoch: 2, iter 1140 = 0.5358887314796448\n",
      "Generator Loss at epoch: 2, iter 1140 = 2.5803050994873047\n",
      "Discriminator Loss at epoch: 2, iter 1150 = 0.49714118242263794\n",
      "Generator Loss at epoch: 2, iter 1150 = 3.4000258445739746\n",
      "Discriminator Loss at epoch: 2, iter 1160 = 0.7323477268218994\n",
      "Generator Loss at epoch: 2, iter 1160 = 4.674424171447754\n",
      "Discriminator Loss at epoch: 2, iter 1170 = 0.561942458152771\n",
      "Generator Loss at epoch: 2, iter 1170 = 4.646781921386719\n",
      "Discriminator Loss at epoch: 2, iter 1180 = 1.0191278457641602\n",
      "Generator Loss at epoch: 2, iter 1180 = 3.200204849243164\n",
      "Discriminator Loss at epoch: 2, iter 1190 = 0.8690578937530518\n",
      "Generator Loss at epoch: 2, iter 1190 = 4.880755424499512\n",
      "Discriminator Loss at epoch: 2, iter 1200 = 0.6408941149711609\n",
      "Generator Loss at epoch: 2, iter 1200 = 4.113796234130859\n",
      "Discriminator Loss at epoch: 2, iter 1210 = 0.34262150526046753\n",
      "Generator Loss at epoch: 2, iter 1210 = 4.049172401428223\n",
      "Discriminator Loss at epoch: 2, iter 1220 = 0.6264029145240784\n",
      "Generator Loss at epoch: 2, iter 1220 = 4.926355361938477\n",
      "Discriminator Loss at epoch: 2, iter 1230 = 0.7426194548606873\n",
      "Generator Loss at epoch: 2, iter 1230 = 3.7142796516418457\n",
      "Discriminator Loss at epoch: 2, iter 1240 = 0.641679048538208\n",
      "Generator Loss at epoch: 2, iter 1240 = 5.279463768005371\n",
      "Discriminator Loss at epoch: 2, iter 1250 = 1.0485174655914307\n",
      "Generator Loss at epoch: 2, iter 1250 = 2.6764047145843506\n",
      "Discriminator Loss at epoch: 2, iter 1260 = 0.26899415254592896\n",
      "Generator Loss at epoch: 2, iter 1260 = 2.905705451965332\n",
      "Discriminator Loss at epoch: 2, iter 1270 = 0.3825976550579071\n",
      "Generator Loss at epoch: 2, iter 1270 = 4.453065872192383\n",
      "Discriminator Loss at epoch: 2, iter 1280 = 0.6655449867248535\n",
      "Generator Loss at epoch: 2, iter 1280 = 4.902284622192383\n",
      "Discriminator Loss at epoch: 2, iter 1290 = 0.38125553727149963\n",
      "Generator Loss at epoch: 2, iter 1290 = 4.504074573516846\n",
      "Discriminator Loss at epoch: 2, iter 1300 = 0.3370477855205536\n",
      "Generator Loss at epoch: 2, iter 1300 = 2.940670967102051\n",
      "Discriminator Loss at epoch: 2, iter 1310 = 0.3863815665245056\n",
      "Generator Loss at epoch: 2, iter 1310 = 2.625021457672119\n",
      "Discriminator Loss at epoch: 2, iter 1320 = 0.7147931456565857\n",
      "Generator Loss at epoch: 2, iter 1320 = 2.2973148822784424\n",
      "Discriminator Loss at epoch: 2, iter 1330 = 0.8352920413017273\n",
      "Generator Loss at epoch: 2, iter 1330 = 3.59958553314209\n",
      "Discriminator Loss at epoch: 2, iter 1340 = 0.26396632194519043\n",
      "Generator Loss at epoch: 2, iter 1340 = 4.697193622589111\n",
      "Discriminator Loss at epoch: 2, iter 1350 = 1.285463809967041\n",
      "Generator Loss at epoch: 2, iter 1350 = 2.4326493740081787\n",
      "Discriminator Loss at epoch: 2, iter 1360 = 0.4483829438686371\n",
      "Generator Loss at epoch: 2, iter 1360 = 3.2893805503845215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss at epoch: 2, iter 1370 = 0.5436238646507263\n",
      "Generator Loss at epoch: 2, iter 1370 = 3.8731579780578613\n",
      "Discriminator Loss at epoch: 2, iter 1380 = 1.0764836072921753\n",
      "Generator Loss at epoch: 2, iter 1380 = 2.589395523071289\n",
      "Discriminator Loss at epoch: 2, iter 1390 = 0.882404625415802\n",
      "Generator Loss at epoch: 2, iter 1390 = 2.447031259536743\n"
     ]
    }
   ],
   "source": [
    "# WARNING: Big dataset is huge, so should use fewer epochs\n",
    "hp2 = HyperParameter(latent_sz=100, in_img_size=64, in_img_channel=3, \n",
    "                     output_dir=\"../generated_imgs\",\n",
    "                     lr=0.0002, beta1=0.5, epochs=10, batch_sz=64)\n",
    "big_dataset = get_data_loader(\"../data/img_align_celeba/\")\n",
    "g2 = GAN(hp2)\n",
    "g2.fit(big_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting its loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
